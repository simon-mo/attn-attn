{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from AttentionModule import Conv2d_Attn\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models, datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_pretrained = models.resnet101(pretrained=True)\n",
    "nn.Conv2d = Conv2d_Attn\n",
    "resnet_attn = models.resnet101()\n",
    "resnet_attn.load_state_dict(resnet_pretrained.state_dict(), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This block turns 'layer1.0.downsample.0.weight' to 'layer1[0].downsample[0].weight'\n",
    "param_keys = list(resnet_attn.state_dict().keys())\n",
    "formatted_keys = []\n",
    "for k in param_keys:\n",
    "    found = re.findall(r'\\.[\\d]{1,2}\\.', k)\n",
    "    if len(found):\n",
    "        for f in found:\n",
    "            k = k.replace(f, '[{}].'.format(f.strip('.')))\n",
    "    formatted_keys.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This block turn off gradient up for all params except attn_weights\n",
    "def turn_off_grad_except(lst=[]):\n",
    "    turning_off_keys = [k for k in formatted_keys for l in lst if l in k]\n",
    "    for k in formatted_keys:\n",
    "        obj = eval('resnet_attn.'+k)\n",
    "        if k in turning_off_keys:\n",
    "            obj.requires_grad = True\n",
    "        else:\n",
    "            obj.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet_attn.fc = nn.Linear(resnet_attn.fc.in_features, 144)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     normalize])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root='../data/train', transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_imgs = len(trainset.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet_attn = resnet_attn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of attention parameters 52672\n"
     ]
    }
   ],
   "source": [
    "total_attn_params = 0\n",
    "for k in formatted_keys:\n",
    "    obj = eval('resnet_attn.'+k)\n",
    "    if 'attn_weights' in k:\n",
    "        total_attn_params += np.prod(obj.shape)\n",
    "print(\"Total number of attention parameters\", total_attn_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the attention parameters to diverge from 1, therefore we penalize element-wise square loss as $\\lambda (1 \\times \\text{# params} - (x - 1)^2)$\n",
    "\n",
    "But this is too big a number,\n",
    "let's try: \n",
    "$- (x - 1)^2$ for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lambda = 1e-1 #set default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params_objs(name, net='resnet_attn'):\n",
    "    res = []\n",
    "    for k in formatted_keys:\n",
    "        obj = eval(f'{net}.'+k)\n",
    "        if name in k:\n",
    "            res.append(obj)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attn_loss(n_params=26560):\n",
    "    attns = get_params_objs('attn_weights')\n",
    "    penality = sum([torch.pow(t - 1,2).mean() for t in attns])\n",
    "#     penality = (1000/n_params)*sum([torch.min(torch.pow(t-2, 2), torch.pow(t, 2)).sum() for t in attns])\n",
    "    return (_lambda)*(-penality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_params_objs('attn_weights'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0\n",
       "[torch.cuda.FloatTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_attn_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_k_epoch(k, add_attn=True, score_epoch=False):\n",
    "    cls_criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, resnet_attn.parameters()))\n",
    "    \n",
    "    for epoch in range(k):\n",
    "        running_loss = 0.0\n",
    "        running_attn_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = resnet_attn(inputs)\n",
    "            clf_loss = cls_criterion(outputs, labels)\n",
    "                        \n",
    "            attn_loss = compute_attn_loss()\n",
    "            \n",
    "            if add_attn:\n",
    "                loss = clf_loss + attn_loss\n",
    "            else:\n",
    "                loss = clf_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += clf_loss.data[0]\n",
    "            running_attn_loss += attn_loss.data[0]\n",
    "\n",
    "            if i % print_every == 0:\n",
    "                print('[%5d] iter, [%2f] epoch, classifer loss: %.3f, attn_loss: %.5f ' %\n",
    "                      (i + 1, i*batch_size/total_imgs, running_loss/print_every, running_attn_loss/print_every))\n",
    "                running_loss = 0.0\n",
    "                running_attn_loss = 0.0\n",
    "        if score_epoch:\n",
    "            print(score(batch_size=32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def score(net=resnet_attn, batch_size=batch_size):\n",
    "    trainset = torchvision.datasets.ImageFolder(root='../data/train', transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "    \n",
    "    valset = torchvision.datasets.ImageFolder(root='../data/val', transform=transform)\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "    \n",
    "    train_correct = 0\n",
    "    val_correct = 0\n",
    "    \n",
    "    for inp, label in tqdm(iter(trainloader)):\n",
    "        _, idx = net(Variable(inp).cuda()).max(1)\n",
    "        train_correct += int(sum(idx.cpu().data == label))\n",
    "    \n",
    "    for inp, label in tqdm(iter(valloader)):\n",
    "        _, idx = net(Variable(inp).cuda()).max(1)\n",
    "        val_correct += int(sum(idx.cpu().data == label))\n",
    "    \n",
    "    return {\n",
    "        'train_accu': train_correct/len(trainset),\n",
    "        'val_accu': val_correct/len(valset)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a fresh fc layer. \n",
    "`turn_off_grad_except([])` turns off grads for all weights but the fc layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, classifer loss: 0.103, attn_loss: 0.00000 \n",
      "[   51] iter, [0.196054] epoch, classifer loss: 4.217, attn_loss: 0.00000 \n",
      "[  101] iter, [0.392109] epoch, classifer loss: 3.421, attn_loss: 0.00000 \n",
      "[  151] iter, [0.588163] epoch, classifer loss: 3.163, attn_loss: 0.00000 \n",
      "[  201] iter, [0.784218] epoch, classifer loss: 3.010, attn_loss: 0.00000 \n",
      "[  251] iter, [0.980272] epoch, classifer loss: 2.986, attn_loss: 0.00000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [01:51<00:00,  2.29it/s]\n",
      "100%|██████████| 55/55 [00:24<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_accu': 0.3851243720132337, 'val_accu': 0.31755986316989737}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "turn_off_grad_except(['fc'])\n",
    "resnet_attn.eval()\n",
    "train_k_epoch(1,score_epoch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, classifer loss: 0.063, attn_loss: 0.00000 \n",
      "[   51] iter, [0.196054] epoch, classifer loss: 2.338, attn_loss: -0.00941 \n",
      "[  101] iter, [0.392109] epoch, classifer loss: 2.213, attn_loss: -0.06377 \n",
      "[  151] iter, [0.588163] epoch, classifer loss: 2.107, attn_loss: -0.20924 \n",
      "[  251] iter, [0.980272] epoch, classifer loss: 2.027, attn_loss: -0.90647 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [01:51<00:00,  2.29it/s]\n",
      "100%|██████████| 55/55 [00:24<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_accu': 0.4810684965077809, 'val_accu': 0.3831242873432155}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, classifer loss: 0.041, attn_loss: -0.02496 \n",
      "[   51] iter, [0.196054] epoch, classifer loss: 1.988, attn_loss: -1.61095 \n",
      "[  101] iter, [0.392109] epoch, classifer loss: 1.954, attn_loss: -2.48404 \n",
      "[  151] iter, [0.588163] epoch, classifer loss: 1.962, attn_loss: -3.62258 \n",
      "[  201] iter, [0.784218] epoch, classifer loss: 1.968, attn_loss: -5.06184 \n",
      "[  251] iter, [0.980272] epoch, classifer loss: 1.918, attn_loss: -6.83983 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [01:51<00:00,  2.29it/s]\n",
      "100%|██████████| 55/55 [00:24<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_accu': 0.5224849895846098, 'val_accu': 0.41163055872291904}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_lambda = 1\n",
    "turn_off_grad_except(['attn_weights'])\n",
    "resnet_attn.eval()\n",
    "train_k_epoch(2,score_epoch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, classifer loss: 0.034, attn_loss: -0.08089 \n",
      "[   51] iter, [0.196054] epoch, classifer loss: 1.846, attn_loss: -4.36156 \n",
      "[  101] iter, [0.392109] epoch, classifer loss: 1.807, attn_loss: -5.03179 \n",
      "[  151] iter, [0.588163] epoch, classifer loss: 1.798, attn_loss: -5.78239 \n",
      "[  201] iter, [0.784218] epoch, classifer loss: 1.821, attn_loss: -6.62259 \n",
      "[  251] iter, [0.980272] epoch, classifer loss: 1.829, attn_loss: -7.55782 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [01:51<00:00,  2.29it/s]\n",
      "100%|██████████| 55/55 [00:24<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_accu': 0.5479720622472736, 'val_accu': 0.4122006841505131}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, classifer loss: 0.027, attn_loss: -0.16350 \n",
      "[   51] iter, [0.196054] epoch, classifer loss: 1.675, attn_loss: -8.72544 \n",
      "[  101] iter, [0.392109] epoch, classifer loss: 1.698, attn_loss: -9.88018 \n",
      "[  151] iter, [0.588163] epoch, classifer loss: 1.727, attn_loss: -11.15379 \n",
      "[  201] iter, [0.784218] epoch, classifer loss: 1.791, attn_loss: -12.54730 \n",
      "[  251] iter, [0.980272] epoch, classifer loss: 1.810, attn_loss: -14.06458 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [01:51<00:00,  2.29it/s]\n",
      "100%|██████████| 55/55 [00:24<00:00,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_accu': 0.5629212106359515, 'val_accu': 0.4161915621436716}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_lambda = 0.5\n",
    "turn_off_grad_except(['attn_weights'])\n",
    "resnet_attn.eval()\n",
    "train_k_epoch(2,score_epoch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, classifer loss: 0.035, attn_loss: -0.06019 \n",
      "[   51] iter, [0.196054] epoch, classifer loss: 1.717, attn_loss: -3.10602 \n",
      "[  101] iter, [0.392109] epoch, classifer loss: 1.728, attn_loss: -3.30089 \n",
      "[  151] iter, [0.588163] epoch, classifer loss: 1.612, attn_loss: -3.50671 \n",
      "[  201] iter, [0.784218] epoch, classifer loss: 1.636, attn_loss: -3.72410 \n",
      "[  251] iter, [0.980272] epoch, classifer loss: 1.690, attn_loss: -3.95235 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [01:52<00:00,  2.28it/s]\n",
      "100%|██████████| 55/55 [00:24<00:00,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_accu': 0.5797083690724176, 'val_accu': 0.4184720638540479}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, classifer loss: 0.027, attn_loss: -0.08192 \n",
      "[   51] iter, [0.196054] epoch, classifer loss: 1.557, attn_loss: -4.21855 \n",
      "[  101] iter, [0.392109] epoch, classifer loss: 1.552, attn_loss: -4.46772 \n",
      "[  151] iter, [0.588163] epoch, classifer loss: 1.622, attn_loss: -4.72873 \n",
      "[  201] iter, [0.784218] epoch, classifer loss: 1.627, attn_loss: -5.00201 \n",
      "[  251] iter, [0.980272] epoch, classifer loss: 1.711, attn_loss: -5.28589 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [01:52<00:00,  2.28it/s]\n",
      "100%|██████████| 55/55 [00:24<00:00,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_accu': 0.5933096434260507, 'val_accu': 0.41733181299885974}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, classifer loss: 0.033, attn_loss: -0.10929 \n",
      "[   51] iter, [0.196054] epoch, classifer loss: 1.620, attn_loss: -5.61851 \n",
      "[  101] iter, [0.392109] epoch, classifer loss: 1.546, attn_loss: -5.92873 \n",
      "[  151] iter, [0.588163] epoch, classifer loss: 1.496, attn_loss: -6.25151 \n",
      "[  201] iter, [0.784218] epoch, classifer loss: 1.556, attn_loss: -6.58654 \n",
      "[  251] iter, [0.980272] epoch, classifer loss: 1.578, attn_loss: -6.93368 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [01:52<00:00,  2.28it/s]\n",
      "100%|██████████| 55/55 [00:24<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_accu': 0.6085038598211003, 'val_accu': 0.42360319270239455}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, classifer loss: 0.032, attn_loss: -0.14302 \n",
      "[   51] iter, [0.196054] epoch, classifer loss: 1.507, attn_loss: -7.33715 \n",
      "[  101] iter, [0.392109] epoch, classifer loss: 1.533, attn_loss: -7.70959 \n",
      "[  151] iter, [0.588163] epoch, classifer loss: 1.514, attn_loss: -8.09485 \n",
      "[  201] iter, [0.784218] epoch, classifer loss: 1.556, attn_loss: -8.49392 \n",
      "[  251] iter, [0.980272] epoch, classifer loss: 1.458, attn_loss: -8.90481 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [01:52<00:00,  2.28it/s]\n",
      "100%|██████████| 55/55 [00:24<00:00,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_accu': 0.615243229996324, 'val_accu': 0.41961231470923605}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, classifer loss: 0.028, attn_loss: -0.18323 \n",
      "[   51] iter, [0.196054] epoch, classifer loss: 1.492, attn_loss: -9.38066 \n",
      "[  101] iter, [0.392109] epoch, classifer loss: 1.517, attn_loss: -9.81832 \n",
      "[  151] iter, [0.588163] epoch, classifer loss: 1.463, attn_loss: -10.26987 \n",
      "[  201] iter, [0.784218] epoch, classifer loss: 1.435, attn_loss: -10.73474 \n",
      "[  251] iter, [0.980272] epoch, classifer loss: 1.478, attn_loss: -11.21244 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [01:52<00:00,  2.28it/s]\n",
      "100%|██████████| 55/55 [00:24<00:00,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_accu': 0.6328881264550913, 'val_accu': 0.411060433295325}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_lambda = 0.1\n",
    "turn_off_grad_except(['attn_weights'])\n",
    "resnet_attn.eval()\n",
    "train_k_epoch(5,score_epoch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks promising, let me train a baseline first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, classifer loss: 0.033, attn_loss: -0.23019 \n",
      "[   51] iter, [0.196054] epoch, classifer loss: 2.036, attn_loss: -11.50928 \n",
      "[  101] iter, [0.392109] epoch, classifer loss: 1.875, attn_loss: -11.50928 \n",
      "[  151] iter, [0.588163] epoch, classifer loss: 1.925, attn_loss: -11.50928 \n",
      "[  201] iter, [0.784218] epoch, classifer loss: 1.932, attn_loss: -11.50928 \n",
      "[  251] iter, [0.980272] epoch, classifer loss: 1.892, attn_loss: -11.50928 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [01:51<00:00,  2.29it/s]\n",
      "100%|██████████| 55/55 [00:24<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_accu': 0.508516113221419, 'val_accu': 0.37058152793614596}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "turn_off_grad_except(['bn'])\n",
    "resnet_attn.eval()\n",
    "train_k_epoch(1,score_epoch=True,add_attn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, classifer loss: 0.030, attn_loss: -0.23019 \n",
      "[   51] iter, [0.196054] epoch, classifer loss: 2.406, attn_loss: -11.50928 \n",
      "[  101] iter, [0.392109] epoch, classifer loss: 2.001, attn_loss: -11.50928 \n",
      "[  151] iter, [0.588163] epoch, classifer loss: 1.896, attn_loss: -11.50928 \n",
      "[  201] iter, [0.784218] epoch, classifer loss: 1.982, attn_loss: -11.50928 \n",
      "[  251] iter, [0.980272] epoch, classifer loss: 1.890, attn_loss: -11.50928 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [01:51<00:00,  2.29it/s]\n",
      "100%|██████████| 55/55 [00:24<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_accu': 0.5950251194706531, 'val_accu': 0.4070695553021665}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "turn_off_grad_except(['fc'])\n",
    "resnet_attn.eval()\n",
    "train_k_epoch(1,score_epoch=True,add_attn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
