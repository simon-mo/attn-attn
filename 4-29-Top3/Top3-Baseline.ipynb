{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from AttentionModule import Conv2d_Attn\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models, datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_pretrained = models.resnet50(pretrained=True)\n",
    "nn.Conv2d = Conv2d_Attn\n",
    "resnet_attn = models.resnet50()\n",
    "resnet_attn.load_state_dict(resnet_pretrained.state_dict(), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This block turns 'layer1.0.downsample.0.weight' to 'layer1[0].downsample[0].weight'\n",
    "param_keys = list(resnet_attn.state_dict().keys())\n",
    "formatted_keys = []\n",
    "for k in param_keys:\n",
    "    found = re.findall(r'\\.[\\d]{1,2}\\.', k)\n",
    "    if len(found):\n",
    "        for f in found:\n",
    "            k = k.replace(f, '[{}].'.format(f.strip('.')))\n",
    "    formatted_keys.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This block turn off gradient up for all params except attn_weights\n",
    "def turn_off_grad_except(lst=[]):\n",
    "    for k in formatted_keys:\n",
    "        obj = eval('resnet_attn.'+k)\n",
    "        for kw in lst:\n",
    "            if not kw in k:\n",
    "                obj.requires_grad = False\n",
    "            else:\n",
    "                obj.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet_attn.fc = nn.Linear(resnet_attn.fc.in_features, 144)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     normalize])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root='../data/train', transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_imgs = len(trainset.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet_attn = resnet_attn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of attention parameters 26560\n"
     ]
    }
   ],
   "source": [
    "total_attn_params = 0\n",
    "for k in formatted_keys:\n",
    "    obj = eval('resnet_attn.'+k)\n",
    "    if 'attn_weights' in k:\n",
    "        total_attn_params += np.prod(obj.shape)\n",
    "print(\"Total number of attention parameters\", total_attn_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the attention parameters to diverge from 1, therefore we penalize element-wise square loss as $\\lambda (1 \\times \\text{# params} - (x - 1)^2)$\n",
    "\n",
    "But this is too big a number,\n",
    "let's try: \n",
    "$- (x - 1)^2$ for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lambda = 1e-2 #set default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params_objs(name, net='resnet_attn'):\n",
    "    res = []\n",
    "    for k in formatted_keys:\n",
    "        obj = eval(f'{net}.'+k)\n",
    "        if name in k:\n",
    "            res.append(obj)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attn_loss(n_params=26560):\n",
    "    attns = get_params_objs('attn_weights')\n",
    "    penality = sum([torch.pow(t - 1,2).mean() for t in attns])\n",
    "    return _lambda*(- penality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_top3():\n",
    "    correct_count = 0\n",
    "    for inp, label in tqdm(iter(valloader)):\n",
    "        _, idx = resnet_attn(Variable(inp).cuda()).topk(3)\n",
    "        lab = Variable(label).cuda()\n",
    "        lab_expand = lab.unsqueeze(1).expand_as(idx)\n",
    "        correct_count += int((idx == lab_expand).sum())\n",
    "    print(correct_count/len(valset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(k=1, add_attn=True, score='val', plot_hist=False):\n",
    "    cls_criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, resnet_attn.parameters()))\n",
    "    \n",
    "    for j in range(k):\n",
    "        running_loss = 0.0\n",
    "        running_attn_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = resnet_attn(inputs)\n",
    "            loss = cls_criterion(outputs, labels)\n",
    "            attn_loss = compute_attn_loss()\n",
    "            if add_attn:\n",
    "                loss += attn_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            running_loss += loss.data[0]\n",
    "            running_attn_loss += attn_loss.data[0]\n",
    "\n",
    "            if i % print_every == 0:\n",
    "                print('[%5d] iter, [%2f] epoch, avg loss: %.3f, attn_loss: %.5f ' %\n",
    "                      (i + 1, i*batch_size/total_imgs, running_loss/print_every, running_attn_loss/print_every))\n",
    "                running_loss = 0.0\n",
    "                running_attn_loss = 0.0\n",
    "        if score == 'val':\n",
    "            score_top3()\n",
    "        if plot_hist:\n",
    "            plot_attn_hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "valset = torchvision.datasets.ImageFolder(root='../data/val', transform=transform)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attn_hist():\n",
    "    attns = get_params_objs('attn_weights')\n",
    "    attns = torch.cat([attn.squeeze() for attn in attns])\n",
    "    attns_arr = attns.data.cpu().numpy()\n",
    "    plt.hist(attns_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, avg loss: 0.100, attn_loss: 0.00000 \n",
      "[   51] iter, [0.196054] epoch, avg loss: 4.266, attn_loss: 0.00000 \n",
      "[  101] iter, [0.392109] epoch, avg loss: 3.487, attn_loss: 0.00000 \n",
      "[  151] iter, [0.588163] epoch, avg loss: 3.229, attn_loss: 0.00000 \n",
      "[  201] iter, [0.784218] epoch, avg loss: 3.028, attn_loss: 0.00000 \n",
      "[  251] iter, [0.980272] epoch, avg loss: 2.957, attn_loss: 0.00000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:13<00:00,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5188141391106044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, avg loss: 0.045, attn_loss: 0.00000 \n",
      "[   51] iter, [0.196054] epoch, avg loss: 2.510, attn_loss: 0.00000 \n",
      "[  101] iter, [0.392109] epoch, avg loss: 2.467, attn_loss: 0.00000 \n",
      "[  151] iter, [0.588163] epoch, avg loss: 2.408, attn_loss: 0.00000 \n",
      "[  201] iter, [0.784218] epoch, avg loss: 2.403, attn_loss: 0.00000 \n",
      "[  251] iter, [0.980272] epoch, avg loss: 2.409, attn_loss: 0.00000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:13<00:00,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5592930444697833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, avg loss: 0.040, attn_loss: 0.00000 \n",
      "[   51] iter, [0.196054] epoch, avg loss: 2.063, attn_loss: 0.00000 \n",
      "[  101] iter, [0.392109] epoch, avg loss: 2.021, attn_loss: 0.00000 \n",
      "[  151] iter, [0.588163] epoch, avg loss: 1.979, attn_loss: 0.00000 \n",
      "[  201] iter, [0.784218] epoch, avg loss: 2.140, attn_loss: 0.00000 \n",
      "[  251] iter, [0.980272] epoch, avg loss: 2.171, attn_loss: 0.00000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:13<00:00,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.556442417331813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, avg loss: 0.032, attn_loss: 0.00000 \n",
      "[   51] iter, [0.196054] epoch, avg loss: 1.838, attn_loss: 0.00000 \n",
      "[  101] iter, [0.392109] epoch, avg loss: 1.804, attn_loss: 0.00000 \n",
      "[  151] iter, [0.588163] epoch, avg loss: 1.804, attn_loss: 0.00000 \n",
      "[  201] iter, [0.784218] epoch, avg loss: 1.841, attn_loss: 0.00000 \n",
      "[  251] iter, [0.980272] epoch, avg loss: 1.880, attn_loss: 0.00000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:13<00:00,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5689851767388826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, avg loss: 0.034, attn_loss: 0.00000 \n",
      "[   51] iter, [0.196054] epoch, avg loss: 1.664, attn_loss: 0.00000 \n",
      "[  101] iter, [0.392109] epoch, avg loss: 1.608, attn_loss: 0.00000 \n",
      "[  151] iter, [0.588163] epoch, avg loss: 1.689, attn_loss: 0.00000 \n",
      "[  201] iter, [0.784218] epoch, avg loss: 1.603, attn_loss: 0.00000 \n",
      "[  251] iter, [0.980272] epoch, avg loss: 1.698, attn_loss: 0.00000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:14<00:00,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5786773090079818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, avg loss: 0.028, attn_loss: 0.00000 \n",
      "[   51] iter, [0.196054] epoch, avg loss: 1.473, attn_loss: 0.00000 \n",
      "[  101] iter, [0.392109] epoch, avg loss: 1.437, attn_loss: 0.00000 \n",
      "[  151] iter, [0.588163] epoch, avg loss: 1.530, attn_loss: 0.00000 \n",
      "[  201] iter, [0.784218] epoch, avg loss: 1.560, attn_loss: 0.00000 \n",
      "[  251] iter, [0.980272] epoch, avg loss: 1.600, attn_loss: 0.00000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:13<00:00,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5746864310148233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, avg loss: 0.029, attn_loss: 0.00000 \n",
      "[   51] iter, [0.196054] epoch, avg loss: 1.296, attn_loss: 0.00000 \n",
      "[  101] iter, [0.392109] epoch, avg loss: 1.440, attn_loss: 0.00000 \n",
      "[  151] iter, [0.588163] epoch, avg loss: 1.376, attn_loss: 0.00000 \n",
      "[  201] iter, [0.784218] epoch, avg loss: 1.457, attn_loss: 0.00000 \n",
      "[  251] iter, [0.980272] epoch, avg loss: 1.484, attn_loss: 0.00000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:13<00:00,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5826681870011402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, avg loss: 0.030, attn_loss: 0.00000 \n",
      "[   51] iter, [0.196054] epoch, avg loss: 1.205, attn_loss: 0.00000 \n",
      "[  101] iter, [0.392109] epoch, avg loss: 1.238, attn_loss: 0.00000 \n",
      "[  151] iter, [0.588163] epoch, avg loss: 1.336, attn_loss: 0.00000 \n",
      "[  201] iter, [0.784218] epoch, avg loss: 1.358, attn_loss: 0.00000 \n",
      "[  251] iter, [0.980272] epoch, avg loss: 1.338, attn_loss: 0.00000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:13<00:00,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5792474344355758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, avg loss: 0.021, attn_loss: 0.00000 \n",
      "[   51] iter, [0.196054] epoch, avg loss: 1.206, attn_loss: 0.00000 \n",
      "[  101] iter, [0.392109] epoch, avg loss: 1.186, attn_loss: 0.00000 \n",
      "[  151] iter, [0.588163] epoch, avg loss: 1.157, attn_loss: 0.00000 \n",
      "[  201] iter, [0.784218] epoch, avg loss: 1.258, attn_loss: 0.00000 \n",
      "[  251] iter, [0.980272] epoch, avg loss: 1.308, attn_loss: 0.00000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:13<00:00,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5917901938426454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, avg loss: 0.019, attn_loss: 0.00000 \n",
      "[   51] iter, [0.196054] epoch, avg loss: 1.144, attn_loss: 0.00000 \n",
      "[  101] iter, [0.392109] epoch, avg loss: 1.118, attn_loss: 0.00000 \n",
      "[  151] iter, [0.588163] epoch, avg loss: 1.136, attn_loss: 0.00000 \n",
      "[  201] iter, [0.784218] epoch, avg loss: 1.175, attn_loss: 0.00000 \n",
      "[  251] iter, [0.980272] epoch, avg loss: 1.194, attn_loss: 0.00000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:14<00:00,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5866590649942988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, avg loss: 0.026, attn_loss: 0.00000 \n",
      "[   51] iter, [0.196054] epoch, avg loss: 0.997, attn_loss: 0.00000 \n",
      "[  101] iter, [0.392109] epoch, avg loss: 1.092, attn_loss: 0.00000 \n",
      "[  151] iter, [0.588163] epoch, avg loss: 1.086, attn_loss: 0.00000 \n",
      "[  201] iter, [0.784218] epoch, avg loss: 1.083, attn_loss: 0.00000 \n",
      "[  251] iter, [0.980272] epoch, avg loss: 1.178, attn_loss: 0.00000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:14<00:00,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5997719498289624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, avg loss: 0.020, attn_loss: 0.00000 \n",
      "[   51] iter, [0.196054] epoch, avg loss: 0.981, attn_loss: 0.00000 \n",
      "[  101] iter, [0.392109] epoch, avg loss: 0.993, attn_loss: 0.00000 \n",
      "[  151] iter, [0.588163] epoch, avg loss: 1.044, attn_loss: 0.00000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-46:\n",
      "Process Process-45:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <bound method DataLoaderIter.__del__ of <torch.utils.data.dataloader.DataLoaderIter object at 0x7faeadc02940>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 331, in __del__\n",
      "    def __del__(self):\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 175, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 4948) exited unexpectedly with exit code 1.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-7dcf052a3a81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mturn_off_grad_except\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mresnet_attn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Turn on batchnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_attn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_hist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-2b2471e8f7c7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(k, add_attn, score, plot_hist)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mattn_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_attn_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0madd_attn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mattn_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-91b3788b8700>\u001b[0m in \u001b[0;36mcompute_attn_loss\u001b[0;34m(n_params)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_attn_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m26560\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mattns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_params_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'attn_weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpenality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_lambda\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mpenality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-91b3788b8700>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_attn_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m26560\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mattns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_params_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'attn_weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpenality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_lambda\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mpenality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "turn_off_grad_except(['fc'])\n",
    "resnet_attn.eval() # Turn on batchnorm\n",
    "train(20, add_attn=False, plot_hist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
