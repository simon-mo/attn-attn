{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from AttentionModule import Conv2d_Attn\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models, datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "incep_pretrained = models.resnet50(pretrained=True)\n",
    "nn.Conv2d = Conv2d_Attn\n",
    "incep = models.resnet50()\n",
    "incep.load_state_dict(incep_pretrained.state_dict(), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "incep.fc = nn.Linear(incep.fc.in_features, 144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block turns 'layer1.0.downsample.0.weight' to 'layer1[0].downsample[0].weight'\n",
    "def get_formatted_keys(network_name):\n",
    "    param_keys = list(eval(network_name).state_dict().keys())\n",
    "    formatted_keys = []\n",
    "    for k in param_keys:\n",
    "        found = re.findall(r'\\.[\\d]{1,2}\\.', k)\n",
    "        if len(found):\n",
    "            for f in found:\n",
    "                k = k.replace(f, '[{}].'.format(f.strip('.')))\n",
    "        formatted_keys.append(k)\n",
    "    return formatted_keys\n",
    "    \n",
    "# This block turn off gradient up for all params except attn_weights\n",
    "def turn_off_grad_except(network_name, lst=[]):\n",
    "    formatted_keys = get_formatted_keys(network_name)\n",
    "    for k in formatted_keys:\n",
    "        obj = eval(f'{network_name}.'+k)\n",
    "        for kw in lst:\n",
    "            if not kw in k:\n",
    "                obj.requires_grad = False\n",
    "            else:\n",
    "                obj.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_off_grad_except('incep', ['fc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        normalize])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root='../data/train', transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "valset = torchvision.datasets.ImageFolder(root='../data/val', transform=transform)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(dirname):\n",
    "    trainset = torchvision.datasets.ImageFolder(root=f'../data/{dirname}', transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "    return trainloader, len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_batch(inp, label, top, network):\n",
    "    _, idx = eval(network)(Variable(inp).cuda()).topk(top)\n",
    "    lab = Variable(label).cuda()\n",
    "    lab_expand = lab.unsqueeze(1).expand_as(idx)\n",
    "    return int((idx == lab_expand).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_data(data_dir, network_name):\n",
    "    trainloader, train_total = get_loader(data_dir)\n",
    "    top3_count = 0\n",
    "    top1_count = 0\n",
    "    for inp, label in iter(trainloader):\n",
    "        top1_count += score_batch(inp, label, 1, network_name)\n",
    "        top3_count += score_batch(inp, label, 3, network_name)\n",
    "    logging.info({\n",
    "        f'{data_dir}_top1': top1_count/train_total,\n",
    "        f'{data_dir}_top3': top3_count/train_total\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(network_name, train=True, val=True, batch_size=32):    \n",
    "    if train:\n",
    "        score_data('train', network_name)\n",
    "    if val:\n",
    "        score_data('val', network_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_opt():\n",
    "    cls_criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, incep.parameters()))\n",
    "    return cls_criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "incep = incep.eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 10\n",
    "total_imgs = len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(message)s', \n",
    "                    filename='../logs/resnet50-l1.log',\n",
    "                    level=logging.INFO,\n",
    "                    filemode='w'\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Retraining Resnet101's FC layer, attn altenrate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of attention parameters 13385920\n"
     ]
    }
   ],
   "source": [
    "total_attn_params = 0\n",
    "for k in get_formatted_keys('incep'):\n",
    "    obj = eval('incep.'+k)\n",
    "    if 'attn_weights' in k:\n",
    "        total_attn_params += np.prod(obj.shape)\n",
    "print(\"Total number of attention parameters\", total_attn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lambda = 1e-2 #set default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params_objs(name, net):\n",
    "    res = []\n",
    "    for k in get_formatted_keys(net):\n",
    "        obj = eval(f'{net}.'+k)\n",
    "        if name in k:\n",
    "            res.append(obj)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attn_loss(n_params=13385920, name='incep'):\n",
    "    attns = get_params_objs('attn_weights', name)\n",
    "    penality = sum([torch.norm(t, p=1) for t in attns])\n",
    "    return _lambda*(penality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one(use_attn=False):\n",
    "    logging.info(f\"Iteration {j}\")\n",
    "    logging.info(f\"Layer {layer}\")\n",
    "    j + 1\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_attn_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = incep(inputs)\n",
    "        loss = cls_criterion(outputs, labels)\n",
    "        if use_attn:\n",
    "            loss += compute_attn_loss('incep')\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.data[0]\n",
    "\n",
    "        if (i+1) % print_every == 0:\n",
    "            logging.info(\n",
    "                '{} iter, {} epoch, avg loss: {} '.format(\n",
    "                    i + 1, \n",
    "                    i*batch_size/total_imgs, \n",
    "                    running_loss/print_every))\n",
    "            running_loss = 0.0\n",
    "            running_attn_loss = 0.0\n",
    "        \n",
    "    logging.info(\"Begin Scoring\")\n",
    "    score('incep', batch_size=64)\n",
    "    logging.info(\"Done Scoring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 'fc'\n",
    "turn_off_grad_except('incep', [layer])\n",
    "cls_criterion, optimizer = get_loss_opt()\n",
    "train_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 'attn'\n",
    "turn_off_grad_except('incep', [layer])\n",
    "cls_criterion, optimizer = get_loss_opt()\n",
    "_ = [train_one(use_attn=True) for _ in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 'fc'\n",
    "turn_off_grad_except('incep', [layer])\n",
    "cls_criterion, optimizer = get_loss_opt()\n",
    "train_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 'attn'\n",
    "turn_off_grad_except('incep', [layer])\n",
    "cls_criterion, optimizer = get_loss_opt()\n",
    "_ = [train_one(use_attn=True) for _ in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(incep, 'resnet101-attn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
