{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models, datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_attn = models.resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This block turns 'layer1.0.downsample.0.weight' to 'layer1[0].downsample[0].weight'\n",
    "param_keys = list(resnet_attn.state_dict().keys())\n",
    "formatted_keys = []\n",
    "for k in param_keys:\n",
    "    found = re.findall(r'\\.[\\d]{1,2}\\.', k)\n",
    "    if len(found):\n",
    "        for f in found:\n",
    "            k = k.replace(f, '[{}].'.format(f.strip('.')))\n",
    "    formatted_keys.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This block turn off gradient up for all params except attn_weights\n",
    "def turn_off_grad_except(lst=[]):\n",
    "    for k in formatted_keys:\n",
    "        obj = eval('resnet_attn.'+k)\n",
    "        for kw in lst:\n",
    "            if not kw in k:\n",
    "                obj.requires_grad = False\n",
    "            else:\n",
    "                obj.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet_attn.fc = nn.Linear(resnet_attn.fc.in_features, 144)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 32\n",
    "# batch_size = 64\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     normalize])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root='../data/train', transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "valset = torchvision.datasets.ImageFolder(root='../data/val', transform=transform)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_imgs = len(trainset.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet_attn = resnet_attn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of attention parameters 0\n"
     ]
    }
   ],
   "source": [
    "total_attn_params = 0\n",
    "for k in formatted_keys:\n",
    "    obj = eval('resnet_attn.'+k)\n",
    "    if 'attn_weights' in k:\n",
    "        total_attn_params += np.prod(obj.shape)\n",
    "print(\"Total number of attention parameters\", total_attn_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the attention parameters to diverge from 1, therefore we penalize element-wise square loss as $\\lambda (1 \\times \\text{# params} - (x - 1)^2)$\n",
    "\n",
    "But this is too big a number,\n",
    "let's try: \n",
    "$- (x - 1)^2$ for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lambda = 1 #set default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params_objs(name, net='resnet_attn'):\n",
    "    res = []\n",
    "    for k in formatted_keys:\n",
    "        obj = eval(f'{net}.'+k)\n",
    "        if name in k:\n",
    "            res.append(obj)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attn_loss(n_params=26560):\n",
    "    attns = get_params_objs('attn_weights')\n",
    "#     penalty = sum([torch.abs(t - 1,2).mean() for t in attns])\n",
    "    penalty = sum([torch.norm(t, p=1) for t in attns])/float(total_attn_params)\n",
    "    return _lambda*(penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_top3(train=True, val=True, partial=True, frac=4):\n",
    "    if train:\n",
    "        correct_count = 0\n",
    "        num_imgs = len(trainset)\n",
    "        if partial:\n",
    "            part = len(trainset)//frac\n",
    "            total = 0\n",
    "            num_imgs = part\n",
    "        \n",
    "        for inp, label in tqdm(iter(trainloader)):\n",
    "            _, idx = resnet_attn(Variable(inp).cuda()).topk(3)\n",
    "            lab = Variable(label).cuda()\n",
    "            lab_expand = lab.unsqueeze(1).expand_as(idx)\n",
    "            correct_count += int((idx == lab_expand).sum())\n",
    "            \n",
    "            if partial:\n",
    "                total += batch_size\n",
    "                if total >= part:\n",
    "                    break\n",
    "            \n",
    "        print({'Train Accuracy': correct_count/num_imgs})\n",
    "    \n",
    "    if val:\n",
    "        correct_count = 0\n",
    "        for inp, label in tqdm(iter(valloader)):\n",
    "            _, idx = resnet_attn(Variable(inp).cuda()).topk(3)\n",
    "            lab = Variable(label).cuda()\n",
    "            lab_expand = lab.unsqueeze(1).expand_as(idx)\n",
    "            correct_count += int((idx == lab_expand).sum())\n",
    "        print({'Val Accuracy': correct_count/len(valset)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attn_hist():\n",
    "    attns = get_params_objs('attn_weights')\n",
    "    attns = torch.cat([attn.view(-1).squeeze() for attn in attns])\n",
    "    attns_arr = attns.data.cpu().numpy()\n",
    "    plt.hist(attns_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_opt():\n",
    "    cls_criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(resnet_attn.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
    "    return cls_criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one():\n",
    "    trainloader, train_total = get_loader('train')\n",
    "\n",
    "    running_cls_loss = 0.0\n",
    "    running_attn_loss = 0.0\n",
    "    top1_count = 0\n",
    "    top3_count = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet_attn(inputs)\n",
    "        cls_loss = cls_criterion(outputs, labels)\n",
    "        loss = cls_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_cls_loss += cls_loss.data[0]\n",
    "        \n",
    "        top1_count += compute_correct(outputs, labels, 1)\n",
    "        top3_count += compute_correct(outputs, labels, 3)\n",
    "\n",
    "        if (i + 1) % print_every == 0:\n",
    "            print_log(\n",
    "                '{} iter, {} epoch, cls loss: {}'.format(\n",
    "                    i + 1,\n",
    "                    i * batch_size / total_imgs,\n",
    "                    running_cls_loss / print_every))\n",
    "            running_cls_loss = 0.0\n",
    "            running_attn_loss = 0.0\n",
    "\n",
    "    print_log(\"Begin Scoring\")\n",
    "    print_log({\n",
    "        f'train_top1': top1_count / train_total,\n",
    "        f'train_top3': top3_count / train_total\n",
    "    })\n",
    "    score('resnet_attn', batch_size=64, train=False)\n",
    "    print_log(\"Done Scoring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(dirname, batch_size=32):\n",
    "    trainset = torchvision.datasets.ImageFolder(root=f'../data/{dirname}', transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=3)\n",
    "    return trainloader, len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(message)s',\n",
    "                    filename='{}'.format('from_scratch.log'),\n",
    "                    level=logging.INFO,\n",
    "                    filemode='w+'\n",
    "                    )\n",
    "\n",
    "\n",
    "def print_log(*string):\n",
    "    print(*string)\n",
    "    logging.info(str(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin\n"
     ]
    }
   ],
   "source": [
    "print_log('Begin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_batch(inp, label, top, network):\n",
    "    _, idx = eval(network)(Variable(inp).cuda()).topk(top)\n",
    "    lab = Variable(label).cuda()\n",
    "    lab_expand = lab.unsqueeze(1).expand_as(idx)\n",
    "    return int((idx == lab_expand).sum())\n",
    "\n",
    "def compute_correct(out, label, top):\n",
    "    _, idx = out.topk(top)\n",
    "    lab_expand = label.unsqueeze(1).expand_as(idx)\n",
    "    return int((idx == lab_expand).sum())\n",
    "\n",
    "\n",
    "def score_data(data_dir, network_name):\n",
    "    trainloader, train_total = get_loader(data_dir, batch_size=64)\n",
    "    top3_count = 0\n",
    "    top1_count = 0\n",
    "    for inp, label in iter(trainloader):\n",
    "        top1_count += score_batch(inp, label, 1, network_name)\n",
    "        top3_count += score_batch(inp, label, 3, network_name)\n",
    "    print_log({\n",
    "        f'{data_dir}_top1': top1_count / train_total,\n",
    "        f'{data_dir}_top3': top3_count / train_total\n",
    "    })\n",
    "\n",
    "\n",
    "def score(network_name, train=True, val=True, batch_size=32):\n",
    "    if train:\n",
    "        score_data('train', network_name)\n",
    "    if val:\n",
    "        score_data('val', network_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 iter, 1.5370665359637299 epoch, cls loss: 9.780503072738647\n",
      "100 iter, 3.105501776743046 epoch, cls loss: 4.381561708450318\n",
      "150 iter, 4.673937017522363 epoch, cls loss: 4.3171054458618165\n",
      "200 iter, 6.242372258301678 epoch, cls loss: 4.236970739364624\n",
      "250 iter, 7.810807499080995 epoch, cls loss: 4.209580683708191\n",
      "Begin Scoring\n",
      "{'train_top1': 0.0654331577012621, 'train_top3': 0.16897439039333415}\n",
      "{'val_top1': 0.07810718358038768, 'val_top3': 0.17103762827822122}\n",
      "Done Scoring\n",
      "50 iter, 1.5370665359637299 epoch, cls loss: 4.23497700214386\n",
      "100 iter, 3.105501776743046 epoch, cls loss: 4.200983171463013\n",
      "150 iter, 4.673937017522363 epoch, cls loss: 4.180145978927612\n",
      "200 iter, 6.242372258301678 epoch, cls loss: 4.219748349189758\n",
      "250 iter, 7.810807499080995 epoch, cls loss: 4.198048677444458\n",
      "Begin Scoring\n",
      "{'train_top1': 0.06972184781276804, 'train_top3': 0.1802475186864355}\n",
      "{'val_top1': 0.07696693272519954, 'val_top3': 0.1750285062713797}\n",
      "Done Scoring\n",
      "50 iter, 1.5370665359637299 epoch, cls loss: 4.265614233016968\n",
      "100 iter, 3.105501776743046 epoch, cls loss: 4.165210943222046\n",
      "150 iter, 4.673937017522363 epoch, cls loss: 4.221151638031006\n",
      "200 iter, 6.242372258301678 epoch, cls loss: 4.168644881248474\n",
      "250 iter, 7.810807499080995 epoch, cls loss: 4.225856261253357\n",
      "Begin Scoring\n",
      "{'train_top1': 0.06751623575542214, 'train_top3': 0.1747334885430707}\n",
      "{'val_top1': 0.07810718358038768, 'val_top3': 0.17730900798175597}\n",
      "Done Scoring\n",
      "50 iter, 1.5370665359637299 epoch, cls loss: 4.231083674430847\n",
      "100 iter, 3.105501776743046 epoch, cls loss: 4.183678150177002\n",
      "150 iter, 4.673937017522363 epoch, cls loss: 4.1881016254425045\n",
      "200 iter, 6.242372258301678 epoch, cls loss: 4.164884285926819\n",
      "250 iter, 7.810807499080995 epoch, cls loss: 4.208395414352417\n",
      "Begin Scoring\n",
      "{'train_top1': 0.07094718784462688, 'train_top3': 0.1825756647469673}\n",
      "{'val_top1': 0.07753705815279362, 'val_top3': 0.17730900798175597}\n",
      "Done Scoring\n",
      "50 iter, 1.5370665359637299 epoch, cls loss: 4.193552513122558\n",
      "100 iter, 3.105501776743046 epoch, cls loss: 4.150018358230591\n",
      "150 iter, 4.673937017522363 epoch, cls loss: 4.138006806373596\n",
      "200 iter, 6.242372258301678 epoch, cls loss: 4.230678558349609\n",
      "250 iter, 7.810807499080995 epoch, cls loss: 4.224202637672424\n",
      "Begin Scoring\n",
      "{'train_top1': 0.07033451782869746, 'train_top3': 0.17595882857492953}\n",
      "{'val_top1': 0.07696693272519954, 'val_top3': 0.17616875712656785}\n",
      "Done Scoring\n",
      "50 iter, 1.5370665359637299 epoch, cls loss: 4.197159352302552\n",
      "100 iter, 3.105501776743046 epoch, cls loss: 4.189385223388672\n",
      "150 iter, 4.673937017522363 epoch, cls loss: 4.184114427566528\n",
      "200 iter, 6.242372258301678 epoch, cls loss: 4.18795241355896\n",
      "250 iter, 7.810807499080995 epoch, cls loss: 4.18686086177826\n",
      "Begin Scoring\n",
      "{'train_top1': 0.07008944982232569, 'train_top3': 0.18061512069599314}\n",
      "{'val_top1': 0.07639680729760548, 'val_top3': 0.17844925883694412}\n",
      "Done Scoring\n",
      "50 iter, 1.5370665359637299 epoch, cls loss: 4.184468860626221\n",
      "100 iter, 3.105501776743046 epoch, cls loss: 4.187540054321289\n",
      "150 iter, 4.673937017522363 epoch, cls loss: 4.20398166179657\n",
      "200 iter, 6.242372258301678 epoch, cls loss: 4.191383609771728\n",
      "250 iter, 7.810807499080995 epoch, cls loss: 4.161302313804627\n",
      "Begin Scoring\n",
      "{'train_top1': 0.07143732385737042, 'train_top3': 0.1809827227055508}\n",
      "{'val_top1': 0.07981755986316989, 'val_top3': 0.17844925883694412}\n",
      "Done Scoring\n",
      "50 iter, 1.5370665359637299 epoch, cls loss: 4.142606525421143\n",
      "100 iter, 3.105501776743046 epoch, cls loss: 4.204831962585449\n",
      "150 iter, 4.673937017522363 epoch, cls loss: 4.180743770599365\n",
      "200 iter, 6.242372258301678 epoch, cls loss: 4.2232650995254515\n",
      "250 iter, 7.810807499080995 epoch, cls loss: 4.155121569633484\n",
      "Begin Scoring\n",
      "{'train_top1': 0.07119225585099866, 'train_top3': 0.1808601887023649}\n",
      "{'val_top1': 0.07753705815279362, 'val_top3': 0.1733181299885975}\n",
      "Done Scoring\n",
      "50 iter, 1.5370665359637299 epoch, cls loss: 4.230651645660401\n",
      "100 iter, 3.105501776743046 epoch, cls loss: 4.145821595191956\n",
      "150 iter, 4.673937017522363 epoch, cls loss: 4.200148210525513\n",
      "200 iter, 6.242372258301678 epoch, cls loss: 4.205105543136597\n",
      "250 iter, 7.810807499080995 epoch, cls loss: 4.138291797637939\n",
      "Begin Scoring\n",
      "{'train_top1': 0.0724175958828575, 'train_top3': 0.18135032471510845}\n",
      "{'val_top1': 0.07696693272519954, 'val_top3': 0.1750285062713797}\n",
      "Done Scoring\n",
      "50 iter, 1.5370665359637299 epoch, cls loss: 4.218301286697388\n",
      "100 iter, 3.105501776743046 epoch, cls loss: 4.195622115135193\n",
      "150 iter, 4.673937017522363 epoch, cls loss: 4.209899826049805\n",
      "200 iter, 6.242372258301678 epoch, cls loss: 4.1707899856567385\n",
      "250 iter, 7.810807499080995 epoch, cls loss: 4.155344290733337\n",
      "Begin Scoring\n",
      "{'train_top1': 0.0684965077809092, 'train_top3': 0.17240534248253891}\n",
      "{'val_top1': 0.07639680729760548, 'val_top3': 0.17844925883694412}\n",
      "Done Scoring\n",
      "50 iter, 1.5370665359637299 epoch, cls loss: 4.214453387260437\n",
      "100 iter, 3.105501776743046 epoch, cls loss: 4.1767532253265385\n",
      "150 iter, 4.673937017522363 epoch, cls loss: 4.1960869836807255\n",
      "200 iter, 6.242372258301678 epoch, cls loss: 4.137241101264953\n",
      "250 iter, 7.810807499080995 epoch, cls loss: 4.169870176315308\n",
      "Begin Scoring\n",
      "{'train_top1': 0.070824653841441, 'train_top3': 0.1770616346036025}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-66:\n",
      "Process Process-64:\n",
      "Process Process-65:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 122, in __getitem__\n",
      "    img = self.loader(path)\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 69, in default_loader\n",
      "    return pil_loader(path)\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 52, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/site-packages/PIL/Image.py\", line 879, in convert\n",
      "    self.load()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <bound method DataLoaderIter.__del__ of <torch.utils.data.dataloader.DataLoaderIter object at 0x7fbd5f767f98>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 333, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 319, in _shutdown_workers\n",
      "    self.data_queue.get()\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 487, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 614, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 14747) exited unexpectedly with exit code 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-f6beef9476b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcls_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_loss_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-644105edfac7>\u001b[0m in \u001b[0;36mtrain_one\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;34mf'train_top3'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtop3_count\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtrain_total\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     })\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'resnet_attn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mprint_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done Scoring\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-b5aaa62917b3>\u001b[0m in \u001b[0;36mscore\u001b[0;34m(network_name, train, val, batch_size)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mscore_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mscore_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-b5aaa62917b3>\u001b[0m in \u001b[0;36mscore_data\u001b[0;34m(data_dir, network_name)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtop1_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtop1_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mscore_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mtop3_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mscore_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     print_log({\n",
      "\u001b[0;32m<ipython-input-24-b5aaa62917b3>\u001b[0m in \u001b[0;36mscore_batch\u001b[0;34m(inp, label, top, network)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscore_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mlab_expand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlab_expand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCudaTransfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i, device, async)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;31m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mprevious_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 14747) exited unexpectedly with exit code 1."
     ]
    }
   ],
   "source": [
    "cls_criterion, optimizer = get_loss_opt()\n",
    "for iteration in range(50):\n",
    "    train_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
