{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from AttentionModule import Conv2d_Attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from AttentionModule import Conv2d_Attn\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models, datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_pretrained = models.resnet50(pretrained=True)\n",
    "nn.Conv2d = Conv2d_Attn\n",
    "resnet_attn = models.resnet50()\n",
    "resnet_attn.load_state_dict(resnet_pretrained.state_dict(), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This block turns 'layer1.0.downsample.0.weight' to 'layer1[0].downsample[0].weight'\n",
    "param_keys = list(resnet_attn.state_dict().keys())\n",
    "formatted_keys = []\n",
    "for k in param_keys:\n",
    "    found = re.findall(r'\\.[\\d]{1,2}\\.', k)\n",
    "    if len(found):\n",
    "        for f in found:\n",
    "            k = k.replace(f, '[{}].'.format(f.strip('.')))\n",
    "    formatted_keys.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This block turn off gradient up for all params except attn_weights\n",
    "def turn_off_grad_except(lst=[]):\n",
    "    for k in formatted_keys:\n",
    "        obj = eval('resnet_attn.'+k)\n",
    "        for kw in lst:\n",
    "            if not kw in k:\n",
    "                obj.requires_grad = False\n",
    "            else:\n",
    "                obj.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet_attn.fc = nn.Linear(resnet_attn.fc.in_features, 144)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     normalize])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root='../data/train', transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "valset = torchvision.datasets.ImageFolder(root='../data/val', transform=transform)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_imgs = len(trainset.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet_attn = resnet_attn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of attention parameters 13385920\n"
     ]
    }
   ],
   "source": [
    "total_attn_params = 0\n",
    "for k in formatted_keys:\n",
    "    obj = eval('resnet_attn.'+k)\n",
    "    if 'attn_weights' in k:\n",
    "        total_attn_params += np.prod(obj.shape)\n",
    "print(\"Total number of attention parameters\", total_attn_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the attention parameters to diverge from 1, therefore we penalize element-wise square loss as $\\lambda (1 \\times \\text{# params} - (x - 1)^2)$\n",
    "\n",
    "But this is too big a number,\n",
    "let's try: \n",
    "$- (x - 1)^2$ for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lambda = 1 #set default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params_objs(name, net='resnet_attn'):\n",
    "    res = []\n",
    "    for k in formatted_keys:\n",
    "        obj = eval(f'{net}.'+k)\n",
    "        if name in k:\n",
    "            res.append(obj)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attn_loss(n_params=26560):\n",
    "    attns = get_params_objs('attn_weights')\n",
    "#     penalty = sum([torch.abs(t - 1,2).mean() for t in attns])\n",
    "    penalty = sum([torch.norm(t, p=1) for t in attns])/float(total_attn_params)\n",
    "    return _lambda*(penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1\n",
       "[torch.cuda.FloatTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_attn_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_top3(train=True, val=True, partial=True, frac=4):\n",
    "    if train:\n",
    "        correct_count = 0\n",
    "        num_imgs = len(trainset)\n",
    "        if partial:\n",
    "            part = len(trainset)//frac\n",
    "            total = 0\n",
    "            num_imgs = part\n",
    "        \n",
    "        for inp, label in tqdm(iter(trainloader)):\n",
    "            _, idx = resnet_attn(Variable(inp).cuda()).topk(3)\n",
    "            lab = Variable(label).cuda()\n",
    "            lab_expand = lab.unsqueeze(1).expand_as(idx)\n",
    "            correct_count += int((idx == lab_expand).sum())\n",
    "            \n",
    "            if partial:\n",
    "                total += batch_size\n",
    "                if total >= part:\n",
    "                    break\n",
    "            \n",
    "        print({'Train Accuracy': correct_count/num_imgs})\n",
    "    \n",
    "    if val:\n",
    "        correct_count = 0\n",
    "        for inp, label in tqdm(iter(valloader)):\n",
    "            _, idx = resnet_attn(Variable(inp).cuda()).topk(3)\n",
    "            lab = Variable(label).cuda()\n",
    "            lab_expand = lab.unsqueeze(1).expand_as(idx)\n",
    "            correct_count += int((idx == lab_expand).sum())\n",
    "        print({'Val Accuracy': correct_count/len(valset)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attn_hist():\n",
    "    attns = get_params_objs('attn_weights')\n",
    "    attns = torch.cat([attn.view(-1).squeeze() for attn in attns])\n",
    "    attns_arr = attns.data.cpu().numpy()\n",
    "    plt.hist(attns_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(k=1, add_attn=True, score=True, plot_hist=False):\n",
    "    cls_criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, resnet_attn.parameters()))\n",
    "    \n",
    "    for j in range(k):\n",
    "        running_loss = 0.0\n",
    "        running_attn_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = resnet_attn(inputs)\n",
    "            loss = cls_criterion(outputs, labels)\n",
    "            attn_loss = compute_attn_loss()\n",
    "            if add_attn:\n",
    "                loss += attn_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.data[0]\n",
    "            running_attn_loss += attn_loss.data[0]\n",
    "\n",
    "            if i % print_every == 0:\n",
    "                print('[%5d] iter, [%2f] epoch, avg loss: %.3f, attn_loss: %.5f ' %\n",
    "                      (i + 1, i*batch_size/total_imgs, running_loss/print_every, running_attn_loss/print_every))\n",
    "                running_loss = 0.0\n",
    "                running_attn_loss = 0.0\n",
    "        if score:\n",
    "            score_top3(False, False)\n",
    "        if plot_hist:\n",
    "            plot_attn_hist()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, avg loss: 0.103, attn_loss: 0.02000 \n",
      "[   51] iter, [0.196054] epoch, avg loss: 4.236, attn_loss: 1.00000 \n",
      "[  101] iter, [0.392109] epoch, avg loss: 3.502, attn_loss: 1.00000 \n",
      "[  151] iter, [0.588163] epoch, avg loss: 3.255, attn_loss: 1.00000 \n",
      "[  201] iter, [0.784218] epoch, avg loss: 2.982, attn_loss: 1.00000 \n",
      "[  251] iter, [0.980272] epoch, avg loss: 2.951, attn_loss: 1.00000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 63/256 [00:16<00:49,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Train Accuracy': 0.5965686274509804}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/55 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/55 [00:00<00:19,  2.78it/s]\u001b[A\n",
      "  4%|▎         | 2/55 [00:00<00:16,  3.23it/s]\u001b[A\n",
      "  5%|▌         | 3/55 [00:00<00:15,  3.42it/s]\u001b[A\n",
      "  7%|▋         | 4/55 [00:01<00:14,  3.53it/s]\u001b[A\n",
      "  9%|▉         | 5/55 [00:01<00:13,  3.59it/s]\u001b[A\n",
      " 11%|█         | 6/55 [00:01<00:13,  3.64it/s]\u001b[A\n",
      " 13%|█▎        | 7/55 [00:01<00:13,  3.67it/s]\u001b[A\n",
      " 15%|█▍        | 8/55 [00:02<00:12,  3.69it/s]\u001b[A\n",
      " 16%|█▋        | 9/55 [00:02<00:12,  3.71it/s]\u001b[A\n",
      " 18%|█▊        | 10/55 [00:02<00:12,  3.73it/s]\u001b[A\n",
      " 20%|██        | 11/55 [00:02<00:11,  3.74it/s]\u001b[A\n",
      " 22%|██▏       | 12/55 [00:03<00:11,  3.75it/s]\u001b[A\n",
      "100%|██████████| 55/55 [00:14<00:00,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Val Accuracy': 0.5256556442417332}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "turn_off_grad_except(['fc'])\n",
    "resnet_attn.eval() # Turn on batchnorm\n",
    "train(1, add_attn=False, plot_hist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, avg loss: 18.367, attn_loss: 18.32249 \n",
      "[   51] iter, [0.196054] epoch, avg loss: 897.191, attn_loss: 895.13967 \n",
      "[  101] iter, [0.392109] epoch, avg loss: 856.306, attn_loss: 854.29277 \n",
      "[  151] iter, [0.588163] epoch, avg loss: 815.566, attn_loss: 813.62514 \n",
      "[  201] iter, [0.784218] epoch, avg loss: 775.010, attn_loss: 773.02423 \n",
      "[  251] iter, [0.980272] epoch, avg loss: 734.550, attn_loss: 732.54824 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 63/256 [00:16<00:50,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Train Accuracy': 0.721078431372549}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/55 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/55 [00:00<00:18,  2.85it/s]\u001b[A\n",
      "  4%|▎         | 2/55 [00:00<00:16,  3.25it/s]\u001b[A\n",
      "  5%|▌         | 3/55 [00:00<00:15,  3.41it/s]\u001b[A\n",
      "  7%|▋         | 4/55 [00:01<00:14,  3.52it/s]\u001b[A\n",
      "  9%|▉         | 5/55 [00:01<00:13,  3.58it/s]\u001b[A\n",
      " 11%|█         | 6/55 [00:01<00:13,  3.62it/s]\u001b[A\n",
      " 13%|█▎        | 7/55 [00:01<00:13,  3.66it/s]\u001b[A\n",
      " 15%|█▍        | 8/55 [00:02<00:12,  3.68it/s]\u001b[A\n",
      " 16%|█▋        | 9/55 [00:02<00:12,  3.70it/s]\u001b[A\n",
      " 18%|█▊        | 10/55 [00:02<00:12,  3.71it/s]\u001b[A\n",
      " 20%|██        | 11/55 [00:02<00:11,  3.72it/s]\u001b[A\n",
      " 22%|██▏       | 12/55 [00:03<00:11,  3.74it/s]\u001b[A\n",
      "100%|██████████| 55/55 [00:14<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Val Accuracy': 0.6242873432155074}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, avg loss: 14.193, attn_loss: 14.15867 \n",
      "[   51] iter, [0.196054] epoch, avg loss: 689.370, attn_loss: 687.64216 \n",
      "[  101] iter, [0.392109] epoch, avg loss: 649.722, attn_loss: 647.90996 \n",
      "[  151] iter, [0.588163] epoch, avg loss: 610.096, attn_loss: 608.27915 \n",
      "[  201] iter, [0.784218] epoch, avg loss: 570.674, attn_loss: 568.78240 \n",
      "[  251] iter, [0.980272] epoch, avg loss: 531.324, attn_loss: 529.43172 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 63/256 [00:16<00:50,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Train Accuracy': 0.7642156862745098}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/55 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/55 [00:00<00:19,  2.82it/s]\u001b[A\n",
      "  4%|▎         | 2/55 [00:00<00:16,  3.20it/s]\u001b[A\n",
      "  5%|▌         | 3/55 [00:00<00:15,  3.38it/s]\u001b[A\n",
      "  7%|▋         | 4/55 [00:01<00:14,  3.48it/s]\u001b[A\n",
      "  9%|▉         | 5/55 [00:01<00:14,  3.55it/s]\u001b[A\n",
      " 11%|█         | 6/55 [00:01<00:13,  3.59it/s]\u001b[A\n",
      " 13%|█▎        | 7/55 [00:01<00:13,  3.62it/s]\u001b[A\n",
      " 15%|█▍        | 8/55 [00:02<00:12,  3.65it/s]\u001b[A\n",
      " 16%|█▋        | 9/55 [00:02<00:12,  3.66it/s]\u001b[A\n",
      " 18%|█▊        | 10/55 [00:02<00:12,  3.68it/s]\u001b[A\n",
      " 20%|██        | 11/55 [00:02<00:11,  3.69it/s]\u001b[A\n",
      "100%|██████████| 55/55 [00:14<00:00,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Val Accuracy': 0.636830102622577}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, avg loss: 10.152, attn_loss: 10.10969 \n",
      "[   51] iter, [0.196054] epoch, avg loss: 487.212, attn_loss: 485.52024 \n",
      "[  101] iter, [0.392109] epoch, avg loss: 448.157, attn_loss: 446.51707 \n",
      "[  151] iter, [0.588163] epoch, avg loss: 409.489, attn_loss: 407.75377 \n",
      "[  201] iter, [0.784218] epoch, avg loss: 371.075, attn_loss: 369.22659 \n",
      "[  251] iter, [0.980272] epoch, avg loss: 333.019, attn_loss: 331.02242 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 63/256 [00:16<00:50,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Train Accuracy': 0.7549019607843137}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/55 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/55 [00:00<00:19,  2.80it/s]\u001b[A\n",
      "  4%|▎         | 2/55 [00:00<00:16,  3.23it/s]\u001b[A\n",
      "  5%|▌         | 3/55 [00:00<00:15,  3.39it/s]\u001b[A\n",
      "  7%|▋         | 4/55 [00:01<00:14,  3.49it/s]\u001b[A\n",
      "  9%|▉         | 5/55 [00:01<00:14,  3.55it/s]\u001b[A\n",
      " 11%|█         | 6/55 [00:01<00:13,  3.59it/s]\u001b[A\n",
      " 13%|█▎        | 7/55 [00:01<00:13,  3.63it/s]\u001b[A\n",
      " 15%|█▍        | 8/55 [00:02<00:12,  3.65it/s]\u001b[A\n",
      " 16%|█▋        | 9/55 [00:02<00:12,  3.67it/s]\u001b[A\n",
      " 18%|█▊        | 10/55 [00:02<00:12,  3.69it/s]\u001b[A\n",
      " 20%|██        | 11/55 [00:02<00:11,  3.70it/s]\u001b[A\n",
      "100%|██████████| 55/55 [00:14<00:00,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Val Accuracy': 0.6345496009122007}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "turn_off_grad_except(['attn_weights'])\n",
    "resnet_attn.eval() # Turn on batchnorm\n",
    "_lambda=1000\n",
    "train(3, add_attn=True, plot_hist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet_attn, '../5-11-retrain/saved_models/l1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_off_grad_except(['bn'])\n",
    "resnet_attn.train() \n",
    "# _lambda=1\n",
    "train(1, add_attn=False, plot_hist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_off_grad_except(['fc'])\n",
    "resnet_attn.eval() \n",
    "# _lambda=1\n",
    "train(1, add_attn=False, plot_hist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_off_grad_except(['attn_weights'])\n",
    "resnet_attn.eval() # Turn on batchnorm\n",
    "# _lambda=1\n",
    "train(1, add_attn=True, plot_hist=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoint, accuracy above is best so far but with very high train accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    testset = torchvision.datasets.ImageFolder(root='../data/test', transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "    \n",
    "    correct_count = 0\n",
    "    for inp, label in tqdm(iter(testloader)):\n",
    "        _, idx = resnet_attn(Variable(inp).cuda()).topk(3)\n",
    "        lab = Variable(label).cuda()\n",
    "        lab_expand = lab.unsqueeze(1).expand_as(idx)\n",
    "        correct_count += int((idx == lab_expand).sum())\n",
    "    print({'Val Accuracy': correct_count/len(testset)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_top1(set_='test'):    \n",
    "    testset = torchvision.datasets.ImageFolder(root='../data/{}'.format(set_), transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "    \n",
    "    correct_count = 0\n",
    "    for inp, label in tqdm(iter(testloader)):\n",
    "        _, idx = resnet_attn(Variable(inp).cuda()).max(1)\n",
    "        lab = Variable(label).cuda()\n",
    "        correct_count += int((idx == lab).sum())\n",
    "    print({'{} Accuracy'.format(set_): correct_count/len(testset)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:13<00:00,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test Accuracy': 0.452480573819486}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "compute_top1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [01:03<00:00,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train Accuracy': 0.6189192500919005}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "compute_top1('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:13<00:00,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val Accuracy': 0.4372862029646522}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "compute_top1('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 63/256 [00:15<00:48,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Train Accuracy': 0.8142156862745098}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/55 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/55 [00:00<00:24,  2.24it/s]\u001b[A\n",
      "  4%|▎         | 2/55 [00:00<00:18,  2.88it/s]\u001b[A\n",
      "  5%|▌         | 3/55 [00:00<00:16,  3.15it/s]\u001b[A\n",
      "  7%|▋         | 4/55 [00:01<00:15,  3.33it/s]\u001b[A\n",
      "  9%|▉         | 5/55 [00:01<00:14,  3.44it/s]\u001b[A\n",
      " 11%|█         | 6/55 [00:01<00:13,  3.52it/s]\u001b[A\n",
      " 13%|█▎        | 7/55 [00:01<00:13,  3.58it/s]\u001b[A\n",
      " 15%|█▍        | 8/55 [00:02<00:12,  3.62it/s]\u001b[A\n",
      " 16%|█▋        | 9/55 [00:02<00:12,  3.66it/s]\u001b[A\n",
      " 18%|█▊        | 10/55 [00:02<00:12,  3.69it/s]\u001b[A\n",
      " 20%|██        | 11/55 [00:02<00:11,  3.71it/s]\u001b[A\n",
      " 22%|██▏       | 12/55 [00:03<00:11,  3.73it/s]\u001b[A\n",
      " 24%|██▎       | 13/55 [00:03<00:11,  3.75it/s]\u001b[A\n",
      " 25%|██▌       | 14/55 [00:03<00:10,  3.76it/s]\u001b[A\n",
      "100%|██████████| 55/55 [00:13<00:00,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Val Accuracy': 0.6533637400228051}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "score_top3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:13<00:00,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Val Accuracy': 0.6449491930663479}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet_attn, 'l1-norm-top3-67.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_attn = torch.load('l1-norm-top3-67.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
