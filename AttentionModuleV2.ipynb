{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import collections\n",
    "from itertools import repeat\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ntuple(n):\n",
    "    def parse(x):\n",
    "        if isinstance(x, collections.Iterable):\n",
    "            return x\n",
    "        return tuple(repeat(x, n))\n",
    "    return parse\n",
    "\n",
    "_pair = _ntuple(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _ConvNd_Attn(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride,\n",
    "                 padding, dilation, transposed, output_padding, groups, bias, attn_init):\n",
    "        super(_ConvNd_Attn, self).__init__()\n",
    "        if in_channels % groups != 0:\n",
    "            raise ValueError('in_channels must be divisible by groups')\n",
    "        if out_channels % groups != 0:\n",
    "            raise ValueError('out_channels must be divisible by groups')\n",
    "            \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels    \n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.transposed = transposed\n",
    "        self.output_padding = output_padding\n",
    "        self.groups = groups\n",
    "        if transposed:\n",
    "            self.weight = Parameter(torch.Tensor(\n",
    "                in_channels, out_channels // groups, *kernel_size))\n",
    "        else:\n",
    "            self.weight = Parameter(torch.Tensor(\n",
    "                out_channels, in_channels // groups, *kernel_size))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        \n",
    "        self.attn_init = attn_init\n",
    "        self.attn_weights = nn.Parameter(torch.FloatTensor(out_channels,1,1,1))\n",
    "            \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        n = self.in_channels\n",
    "        for k in self.kernel_size:\n",
    "            n *= k\n",
    "        stdv = 1. / math.sqrt(n)\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "            \n",
    "        self.attn_weights.data.fill_(self.attn_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d_Attn(_ConvNd_Attn):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1, bias=True, attn_init=1.0):\n",
    "        kernel_size = _pair(kernel_size)\n",
    "        stride = _pair(stride)\n",
    "        padding = _pair(padding)\n",
    "        dilation = _pair(dilation)\n",
    "        super(Conv2d_Attn, self).__init__(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation,\n",
    "            False, _pair(0), groups, bias, attn_init=attn_init)\n",
    "\n",
    "    def forward(self, input):\n",
    "        attn_paid = self.weight*self.attn_weights\n",
    "        return F.conv2d(input, attn_paid, self.bias, self.stride,\n",
    "                        self.padding, self.dilation, self.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attn_module_test_same_weight():\n",
    "    in_channels = 4\n",
    "    out_channels = 2\n",
    "    kernel_size = 1\n",
    "    \n",
    "    c_attn = Conv2d_Attn(in_channels, out_channels, kernel_size, bias=False)\n",
    "    c = nn.Conv2d(in_channels, out_channels, kernel_size, bias=False)\n",
    "    \n",
    "    inp = Variable(torch.ones(2,4,2,2))\n",
    "    c.weight = c_attn.weight\n",
    "    \n",
    "    c_attn_result = c_attn(inp)\n",
    "    c_result = c(inp)\n",
    "    \n",
    "    assert c_attn_result.data.equal(c_result.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attn_module_test_05_weight():\n",
    "    in_channels = 4\n",
    "    out_channels = 2\n",
    "    kernel_size = 1\n",
    "    \n",
    "    c_attn = Conv2d_Attn(in_channels, out_channels, kernel_size, bias=False, attn_init=0.5)\n",
    "    c = nn.Conv2d(in_channels, out_channels, kernel_size, bias=False)\n",
    "    \n",
    "    inp = Variable(torch.ones(2,4,2,2))\n",
    "    c.weight = c_attn.weight\n",
    "    \n",
    "    c_attn_result = c_attn(inp)\n",
    "    c_result = c(inp)\n",
    "    \n",
    "    assert c_attn_result.data.equal(c_result.data/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attn_module_test_diff_weight():\n",
    "    in_channels = 4\n",
    "    out_channels = 2\n",
    "    kernel_size = 1\n",
    "    \n",
    "    c_attn = Conv2d_Attn(in_channels, out_channels, kernel_size, bias=False)\n",
    "    rand_weights = torch.rand(out_channels,1,1,1)\n",
    "    c_attn.attn_weights.data = c_attn.attn_weights.data*rand_weights\n",
    "    \n",
    "    c = nn.Conv2d(in_channels, out_channels, kernel_size, bias=False)\n",
    "    \n",
    "    inp = Variable(torch.ones(2,4,2,2))\n",
    "    c.weight = c_attn.weight\n",
    "    \n",
    "    c_attn_result = c_attn(inp)\n",
    "    c_result = c(inp)\n",
    "    \n",
    "    rand_weights_on_data = rand_weights.permute(1,0,2,3)\n",
    "    assert np.isclose(c_attn_result.data.sum(),\n",
    "                      ((c_result.data*rand_weights_on_data).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_attn_module():\n",
    "    attn_module_test_same_weight()\n",
    "    attn_module_test_05_weight()\n",
    "    attn_module_test_diff_weight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    test_attn_module()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
