{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AttentionModule import Conv2d_Attn\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models, datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_pretrained = models.resnet50(pretrained=True)\n",
    "nn.Conv2d = Conv2d_Attn\n",
    "resnet_attn = models.resnet50()\n",
    "    \n",
    "resnet_attn.load_state_dict(resnet_pretrained.state_dict(), strict=False)\n",
    "# print(resnet_pretrained.state_dist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This block turns 'layer1.0.downsample.0.weight' to 'layer1[0].downsample[0].weight'\n",
    "param_keys = list(resnet_attn.state_dict().keys())\n",
    "formatted_keys = []\n",
    "for k in param_keys:\n",
    "    found = re.findall(r'\\.[\\d]{1,2}\\.', k)\n",
    "    if len(found):\n",
    "        for f in found:\n",
    "            k = k.replace(f, '[{}].'.format(f.strip('.')))\n",
    "    formatted_keys.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This block turn off gradient up for all params except attn_weights\n",
    "def turn_off_grad_except(lst=[]):\n",
    "    turning_off_keys = [k for k in formatted_keys for l in lst if l in k]\n",
    "    for k in formatted_keys:\n",
    "        obj = eval('resnet_attn.'+k)\n",
    "        if k in turning_off_keys:\n",
    "            print(k)\n",
    "            obj.requires_grad = True\n",
    "        else:\n",
    "            obj.requires_grad = False\n",
    "    \n",
    "\n",
    "def turn_on_layer4_conv_weight():\n",
    "    for k in range(3):\n",
    "        for j in range(1, 4):\n",
    "            eval('resnet_attn.layer4[{}].conv{}.weight'.format(k, j)).requires_gred = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet_attn.fc = nn.Linear(resnet_attn.fc.in_features, 144)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     normalize])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root='./data/train', transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_imgs = len(trainset.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet_attn = resnet_attn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of attention parameters 26560\n"
     ]
    }
   ],
   "source": [
    "total_attn_params = 0\n",
    "for k in formatted_keys:\n",
    "    obj = eval('resnet_attn.'+k)\n",
    "    if 'attn_weights' in k:\n",
    "        total_attn_params += np.prod(obj.shape)\n",
    "print(\"Total number of attention parameters\", total_attn_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the attention parameters to diverge from 1, therefore we penalize element-wise square loss as $\\lambda (1 \\times \\text{# params} - (x - 1)^2)$\n",
    "\n",
    "But this is too big a number,\n",
    "let's try: \n",
    "$- (x - 1)^2$ for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lambda = 1e-1 #set default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params_objs(name, net='resnet_attn'):\n",
    "    res = []\n",
    "    for k in formatted_keys:\n",
    "        obj = eval('{}.'.format(net)+k)\n",
    "        if name in k:\n",
    "            res.append(obj)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attn_loss(n_params=26560):\n",
    "    attns = get_params_objs('attn_weights')\n",
    "#     penality = sum([torch.pow(t - 1,2).mean() for t in attns])\n",
    "    penality = (1000/n_params)*sum([torch.min(torch.pow(t-2, 2), torch.pow(t, 2)).sum() for t in attns])\n",
    "    return (_lambda)*(penality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_params_objs('attn_weights'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(100.0000, device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_attn_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_k_epoch(k, add_attn=True, score_epoch=False):\n",
    "    cls_criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, resnet_attn.parameters()))\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    best_accu = 0\n",
    "    best_model_wts = {}\n",
    "    \n",
    "    for epoch in range(k):\n",
    "        running_loss = 0.0\n",
    "        running_attn_loss = 0.0\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = resnet_attn(inputs)\n",
    "            clf_loss = cls_criterion(outputs, labels)\n",
    "                        \n",
    "            attn_loss = compute_attn_loss()\n",
    "            \n",
    "            if add_attn:\n",
    "                loss = clf_loss + attn_loss\n",
    "            else:\n",
    "                loss = clf_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += clf_loss.data[0]\n",
    "            running_attn_loss += attn_loss.data[0]\n",
    "\n",
    "            if i % print_every == 0:\n",
    "                print('[%5d] iter, [%2f] epoch, classifer loss: %.3f, attn_loss: %.5f' %\n",
    "                      (i + 1, i*batch_size/total_imgs, running_loss/print_every, running_attn_loss/print_every))\n",
    "                running_loss = 0.0\n",
    "                running_attn_loss = 0.0\n",
    "        if score_epoch:\n",
    "            dic = score(batch_size=32)\n",
    "            e_time = time.time() - start\n",
    "            dic['time_elapsed'] = '{:.0f}m {:.0f}s'.format(e_time // 60, e_time%60)\n",
    "            print(dic)\n",
    "            \n",
    "            if dic['val_accu_top1'] > best_accu:\n",
    "                best_accu = dic['val_accu_top1']\n",
    "                best_model_wts = copy.deepcopy(resnet_attn.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def score(net=resnet_attn, batch_size=batch_size):\n",
    "    trainset = torchvision.datasets.ImageFolder(root='./data/train', transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "    \n",
    "    valset = torchvision.datasets.ImageFolder(root='./data/val', transform=transform)\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "    \n",
    "    train_correct = 0\n",
    "    val_correct_top1 = 0\n",
    "    val_correct_top3 = 0\n",
    "    val_correct_top5 = 0\n",
    "    \n",
    "    for inp, label in tqdm(iter(valloader)):\n",
    "        _, idx = net(Variable(inp).cuda()).topk(1)\n",
    "        val_correct_top1 += int(sum([label[i] in idx.cpu().data[i] for i in range(len(idx))]))\n",
    "        \n",
    "        _, idx = net(Variable(inp).cuda()).topk(3)\n",
    "        val_correct_top3 += int(sum([label[i] in idx.cpu().data[i] for i in range(len(idx))]))\n",
    "        \n",
    "        _, idx = net(Variable(inp).cuda()).topk(5)\n",
    "        val_correct_top5 += int(sum([label[i] in idx.cpu().data[i] for i in range(len(idx))]))\n",
    "        \n",
    "    for inp, label in tqdm(iter(trainloader)):\n",
    "        _, idx = net(Variable(inp).cuda()).topk(1)\n",
    "        train_correct += int(sum([label[i] in idx.cpu().data[i] for i in range(len(idx))]))\n",
    "    \n",
    "    return {\n",
    "        'train_accu': train_correct/len(trainset),\n",
    "        'val_accu_top1': val_correct_top1/len(valset),\n",
    "        'val_accu_top3': val_correct_top3/len(valset),\n",
    "        'val_accu_top5': val_correct_top5/len(valset)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a fresh fc layer. \n",
    "`turn_off_grad_except([])` turns off grads for all weights but the fc layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.attn_weights\n",
      "layer1[0].conv1.attn_weights\n",
      "layer1[0].conv2.attn_weights\n",
      "layer1[0].conv3.attn_weights\n",
      "layer1[0].downsample[0].attn_weights\n",
      "layer1[1].conv1.attn_weights\n",
      "layer1[1].conv2.attn_weights\n",
      "layer1[1].conv3.attn_weights\n",
      "layer1[2].conv1.attn_weights\n",
      "layer1[2].conv2.attn_weights\n",
      "layer1[2].conv3.attn_weights\n",
      "layer2[0].conv1.attn_weights\n",
      "layer2[0].conv2.attn_weights\n",
      "layer2[0].conv3.attn_weights\n",
      "layer2[0].downsample[0].attn_weights\n",
      "layer2[1].conv1.attn_weights\n",
      "layer2[1].conv2.attn_weights\n",
      "layer2[1].conv3.attn_weights\n",
      "layer2[2].conv1.attn_weights\n",
      "layer2[2].conv2.attn_weights\n",
      "layer2[2].conv3.attn_weights\n",
      "layer2[3].conv1.attn_weights\n",
      "layer2[3].conv2.attn_weights\n",
      "layer2[3].conv3.attn_weights\n",
      "layer3[0].conv1.attn_weights\n",
      "layer3[0].conv2.attn_weights\n",
      "layer3[0].conv3.attn_weights\n",
      "layer3[0].downsample[0].attn_weights\n",
      "layer3[1].conv1.attn_weights\n",
      "layer3[1].conv2.attn_weights\n",
      "layer3[1].conv3.attn_weights\n",
      "layer3[2].conv1.attn_weights\n",
      "layer3[2].conv2.attn_weights\n",
      "layer3[2].conv3.attn_weights\n",
      "layer3[3].conv1.attn_weights\n",
      "layer3[3].conv2.attn_weights\n",
      "layer3[3].conv3.attn_weights\n",
      "layer3[4].conv1.attn_weights\n",
      "layer3[4].conv2.attn_weights\n",
      "layer3[4].conv3.attn_weights\n",
      "layer3[5].conv1.attn_weights\n",
      "layer3[5].conv2.attn_weights\n",
      "layer3[5].conv3.attn_weights\n",
      "layer4[0].conv1.attn_weights\n",
      "layer4[0].conv2.attn_weights\n",
      "layer4[0].conv3.attn_weights\n",
      "layer4[0].downsample[0].attn_weights\n",
      "layer4[1].conv1.attn_weights\n",
      "layer4[1].conv2.attn_weights\n",
      "layer4[1].conv3.attn_weights\n",
      "layer4[2].conv1.attn_weights\n",
      "layer4[2].conv2.attn_weights\n",
      "layer4[2].conv3.attn_weights\n",
      "fc.weight\n",
      "fc.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:32: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:33: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, classifer loss: 0.256, attn_loss: 5.00000\n",
      "[   21] iter, [0.078422] epoch, classifer loss: 4.690, attn_loss: 97.94265\n",
      "[   41] iter, [0.156844] epoch, classifer loss: 4.291, attn_loss: 94.12140\n",
      "[   61] iter, [0.235265] epoch, classifer loss: 3.915, attn_loss: 90.41732\n",
      "[   81] iter, [0.313687] epoch, classifer loss: 3.793, attn_loss: 86.83248\n",
      "[  101] iter, [0.392109] epoch, classifer loss: 3.597, attn_loss: 83.37243\n",
      "[  121] iter, [0.470531] epoch, classifer loss: 3.679, attn_loss: 80.03396\n",
      "[  141] iter, [0.548952] epoch, classifer loss: 3.450, attn_loss: 76.81706\n",
      "[  161] iter, [0.627374] epoch, classifer loss: 3.347, attn_loss: 73.70966\n",
      "[  181] iter, [0.705796] epoch, classifer loss: 3.520, attn_loss: 70.71809\n",
      "[  201] iter, [0.784218] epoch, classifer loss: 3.468, attn_loss: 67.83167\n",
      "[  221] iter, [0.862639] epoch, classifer loss: 3.379, attn_loss: 65.04615\n",
      "[  241] iter, [0.941061] epoch, classifer loss: 3.514, attn_loss: 62.35752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:43<00:00,  1.27it/s]\n",
      "100%|██████████| 256/256 [01:07<00:00,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_accu_top1': 0.2331812998859749, 'val_accu_top3': 0.3973774230330673, 'time_elapsed': '5m 12s', 'val_accu_top5': 0.47206385404789053, 'train_accu': 0.2609974267859331}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, classifer loss: 0.181, attn_loss: 2.95284\n",
      "[   21] iter, [0.078422] epoch, classifer loss: 3.158, attn_loss: 57.75646\n",
      "[   41] iter, [0.156844] epoch, classifer loss: 3.095, attn_loss: 55.34735\n",
      "[   61] iter, [0.235265] epoch, classifer loss: 3.139, attn_loss: 53.02212\n",
      "[   81] iter, [0.313687] epoch, classifer loss: 3.279, attn_loss: 50.77555\n",
      "[  101] iter, [0.392109] epoch, classifer loss: 3.243, attn_loss: 48.61993\n",
      "[  121] iter, [0.470531] epoch, classifer loss: 3.425, attn_loss: 46.53752\n",
      "[  141] iter, [0.548952] epoch, classifer loss: 3.249, attn_loss: 44.53165\n",
      "[  161] iter, [0.627374] epoch, classifer loss: 3.187, attn_loss: 42.59468\n",
      "[  181] iter, [0.705796] epoch, classifer loss: 3.501, attn_loss: 40.74060\n",
      "[  201] iter, [0.784218] epoch, classifer loss: 3.404, attn_loss: 38.95414\n",
      "[  221] iter, [0.862639] epoch, classifer loss: 3.204, attn_loss: 37.23981\n",
      "[  241] iter, [0.941061] epoch, classifer loss: 3.467, attn_loss: 35.58322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:43<00:00,  1.27it/s]\n",
      "100%|██████████| 256/256 [01:07<00:00,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_accu_top1': 0.17616875712656785, 'val_accu_top3': 0.35860889395667045, 'time_elapsed': '10m 28s', 'val_accu_top5': 0.4549600912200684, 'train_accu': 0.257934076706286}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, classifer loss: 0.132, attn_loss: 1.67790\n",
      "[   21] iter, [0.078422] epoch, classifer loss: 3.170, attn_loss: 32.76477\n",
      "[   41] iter, [0.156844] epoch, classifer loss: 3.084, attn_loss: 31.29860\n",
      "[   61] iter, [0.235265] epoch, classifer loss: 3.141, attn_loss: 29.88766\n",
      "[   81] iter, [0.313687] epoch, classifer loss: 3.234, attn_loss: 28.53258\n",
      "[  101] iter, [0.392109] epoch, classifer loss: 3.322, attn_loss: 27.23943\n",
      "[  121] iter, [0.470531] epoch, classifer loss: 3.304, attn_loss: 26.00547\n",
      "[  141] iter, [0.548952] epoch, classifer loss: 3.286, attn_loss: 24.82340\n",
      "[  161] iter, [0.627374] epoch, classifer loss: 3.310, attn_loss: 23.68148\n",
      "[  181] iter, [0.705796] epoch, classifer loss: 3.519, attn_loss: 22.58718\n",
      "[  201] iter, [0.784218] epoch, classifer loss: 3.506, attn_loss: 21.53987\n",
      "[  221] iter, [0.862639] epoch, classifer loss: 3.441, attn_loss: 20.54478\n",
      "[  241] iter, [0.941061] epoch, classifer loss: 3.437, attn_loss: 19.59096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:43<00:00,  1.27it/s]\n",
      "100%|██████████| 256/256 [01:08<00:00,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_accu_top1': 0.18700114025085518, 'val_accu_top3': 0.3392246294184721, 'time_elapsed': '15m 44s', 'val_accu_top5': 0.42930444697833525, 'train_accu': 0.25070457051831885}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, classifer loss: 0.153, attn_loss: 0.92158\n",
      "[   21] iter, [0.078422] epoch, classifer loss: 3.179, attn_loss: 17.97851\n",
      "[   41] iter, [0.156844] epoch, classifer loss: 3.128, attn_loss: 17.15398\n",
      "[   61] iter, [0.235265] epoch, classifer loss: 3.344, attn_loss: 16.36631\n",
      "[   81] iter, [0.313687] epoch, classifer loss: 3.181, attn_loss: 15.61866\n",
      "[  101] iter, [0.392109] epoch, classifer loss: 3.285, attn_loss: 14.90586\n",
      "[  121] iter, [0.470531] epoch, classifer loss: 3.303, attn_loss: 14.22659\n",
      "[  141] iter, [0.548952] epoch, classifer loss: 3.301, attn_loss: 13.57901\n",
      "[  161] iter, [0.627374] epoch, classifer loss: 3.337, attn_loss: 12.96369\n",
      "[  181] iter, [0.705796] epoch, classifer loss: 3.352, attn_loss: 12.37593\n",
      "[  201] iter, [0.784218] epoch, classifer loss: 3.371, attn_loss: 11.81709\n",
      "[  221] iter, [0.862639] epoch, classifer loss: 3.404, attn_loss: 11.28897\n",
      "[  241] iter, [0.941061] epoch, classifer loss: 3.360, attn_loss: 10.78867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:43<00:00,  1.27it/s]\n",
      "100%|██████████| 256/256 [01:07<00:00,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_accu_top1': 0.15507411630558723, 'val_accu_top3': 0.314709236031927, 'time_elapsed': '21m 0s', 'val_accu_top5': 0.40992018244013684, 'train_accu': 0.22595270187477026}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, classifer loss: 0.150, attn_loss: 0.50938\n",
      "[   21] iter, [0.078422] epoch, classifer loss: 3.101, attn_loss: 9.95232\n",
      "[   41] iter, [0.156844] epoch, classifer loss: 3.131, attn_loss: 9.52628\n",
      "[   61] iter, [0.235265] epoch, classifer loss: 3.099, attn_loss: 9.12119\n",
      "[   81] iter, [0.313687] epoch, classifer loss: 3.193, attn_loss: 8.73724\n",
      "[  101] iter, [0.392109] epoch, classifer loss: 3.209, attn_loss: 8.37405\n",
      "[  121] iter, [0.470531] epoch, classifer loss: 3.149, attn_loss: 8.03237\n",
      "[  141] iter, [0.548952] epoch, classifer loss: 3.184, attn_loss: 7.71067\n",
      "[  161] iter, [0.627374] epoch, classifer loss: 3.345, attn_loss: 7.40278\n",
      "[  181] iter, [0.705796] epoch, classifer loss: 3.363, attn_loss: 7.11312\n",
      "[  201] iter, [0.784218] epoch, classifer loss: 3.374, attn_loss: 6.83901\n",
      "[  221] iter, [0.862639] epoch, classifer loss: 3.260, attn_loss: 6.57811\n",
      "[  241] iter, [0.941061] epoch, classifer loss: 3.232, attn_loss: 6.33445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:43<00:00,  1.27it/s]\n",
      "100%|██████████| 256/256 [01:07<00:00,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_accu_top1': 0.15792474344355759, 'val_accu_top3': 0.32668187001140253, 'time_elapsed': '26m 16s', 'val_accu_top5': 0.41733181299885974, 'train_accu': 0.2302413919862762}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, classifer loss: 0.165, attn_loss: 0.30217\n",
      "[   21] iter, [0.078422] epoch, classifer loss: 3.144, attn_loss: 5.92641\n",
      "[   41] iter, [0.156844] epoch, classifer loss: 3.196, attn_loss: 5.72224\n",
      "[   61] iter, [0.235265] epoch, classifer loss: 3.065, attn_loss: 5.53335\n",
      "[   81] iter, [0.313687] epoch, classifer loss: 3.138, attn_loss: 5.35674\n",
      "[  101] iter, [0.392109] epoch, classifer loss: 3.227, attn_loss: 5.18606\n",
      "[  121] iter, [0.470531] epoch, classifer loss: 3.180, attn_loss: 5.02392\n",
      "[  141] iter, [0.548952] epoch, classifer loss: 3.204, attn_loss: 4.87075\n",
      "[  161] iter, [0.627374] epoch, classifer loss: 3.131, attn_loss: 4.72824\n",
      "[  181] iter, [0.705796] epoch, classifer loss: 3.161, attn_loss: 4.59314\n",
      "[  201] iter, [0.784218] epoch, classifer loss: 3.078, attn_loss: 4.46809\n",
      "[  221] iter, [0.862639] epoch, classifer loss: 3.273, attn_loss: 4.34773\n",
      "[  241] iter, [0.941061] epoch, classifer loss: 3.175, attn_loss: 4.23372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:43<00:00,  1.27it/s]\n",
      "100%|██████████| 256/256 [01:07<00:00,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_accu_top1': 0.1847206385404789, 'val_accu_top3': 0.34150513112884834, 'time_elapsed': '31m 31s', 'val_accu_top5': 0.43443557582668185, 'train_accu': 0.24531307437813993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, classifer loss: 0.177, attn_loss: 0.20473\n",
      "[   21] iter, [0.078422] epoch, classifer loss: 3.034, attn_loss: 4.03961\n",
      "[   41] iter, [0.156844] epoch, classifer loss: 3.087, attn_loss: 3.94451\n",
      "[   61] iter, [0.235265] epoch, classifer loss: 3.176, attn_loss: 3.85503\n",
      "[   81] iter, [0.313687] epoch, classifer loss: 3.075, attn_loss: 3.76849\n",
      "[  101] iter, [0.392109] epoch, classifer loss: 3.022, attn_loss: 3.68868\n",
      "[  121] iter, [0.470531] epoch, classifer loss: 3.092, attn_loss: 3.61417\n",
      "[  141] iter, [0.548952] epoch, classifer loss: 3.093, attn_loss: 3.54209\n",
      "[  161] iter, [0.627374] epoch, classifer loss: 3.163, attn_loss: 3.47374\n",
      "[  181] iter, [0.705796] epoch, classifer loss: 3.238, attn_loss: 3.40587\n",
      "[  201] iter, [0.784218] epoch, classifer loss: 3.182, attn_loss: 3.33971\n",
      "[  221] iter, [0.862639] epoch, classifer loss: 3.261, attn_loss: 3.27837\n",
      "[  241] iter, [0.941061] epoch, classifer loss: 3.055, attn_loss: 3.22171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:43<00:00,  1.28it/s]\n",
      "100%|██████████| 256/256 [01:07<00:00,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_accu_top1': 0.17730900798175597, 'val_accu_top3': 0.3255416191562144, 'time_elapsed': '36m 45s', 'val_accu_top5': 0.41961231470923605, 'train_accu': 0.2348976841073398}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, classifer loss: 0.157, attn_loss: 0.15749\n",
      "[   21] iter, [0.078422] epoch, classifer loss: 3.087, attn_loss: 3.11999\n",
      "[   41] iter, [0.156844] epoch, classifer loss: 2.969, attn_loss: 3.06832\n",
      "[   61] iter, [0.235265] epoch, classifer loss: 2.769, attn_loss: 1.58611\n",
      "[   81] iter, [0.313687] epoch, classifer loss: 2.725, attn_loss: 1.57873\n",
      "[  101] iter, [0.392109] epoch, classifer loss: 2.785, attn_loss: 1.57338\n",
      "[  121] iter, [0.470531] epoch, classifer loss: 2.807, attn_loss: 1.56853\n",
      "[  141] iter, [0.548952] epoch, classifer loss: 2.807, attn_loss: 1.56427\n",
      "[  161] iter, [0.627374] epoch, classifer loss: 2.827, attn_loss: 1.55931\n",
      "[  181] iter, [0.705796] epoch, classifer loss: 2.792, attn_loss: 1.55274\n",
      "[  101] iter, [0.392109] epoch, classifer loss: 2.239, attn_loss: 1.19773\n",
      "[  121] iter, [0.470531] epoch, classifer loss: 2.292, attn_loss: 1.19524\n",
      "[  141] iter, [0.548952] epoch, classifer loss: 2.245, attn_loss: 1.19603\n",
      "[  161] iter, [0.627374] epoch, classifer loss: 2.214, attn_loss: 1.19619\n",
      "[  181] iter, [0.705796] epoch, classifer loss: 2.284, attn_loss: 1.19489\n",
      "[  201] iter, [0.784218] epoch, classifer loss: 2.310, attn_loss: 1.19306\n",
      "[  221] iter, [0.862639] epoch, classifer loss: 2.205, attn_loss: 1.19262\n",
      "[  241] iter, [0.941061] epoch, classifer loss: 2.352, attn_loss: 1.19219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:42<00:00,  1.29it/s]\n",
      "100%|██████████| 256/256 [01:07<00:00,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_accu_top1': 0.16875712656784492, 'val_accu_top3': 0.3312428734321551, 'time_elapsed': '135m 52s', 'val_accu_top5': 0.41961231470923605, 'train_accu': 0.44161254748192624}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, classifer loss: 0.112, attn_loss: 0.05952\n",
      "[   21] iter, [0.078422] epoch, classifer loss: 2.239, attn_loss: 1.18955\n",
      "[   41] iter, [0.156844] epoch, classifer loss: 2.037, attn_loss: 1.18814\n",
      "[   61] iter, [0.235265] epoch, classifer loss: 2.152, attn_loss: 1.18886\n",
      "[   81] iter, [0.313687] epoch, classifer loss: 2.186, attn_loss: 1.18869\n",
      "[  101] iter, [0.392109] epoch, classifer loss: 2.164, attn_loss: 1.18980\n",
      "[  121] iter, [0.470531] epoch, classifer loss: 2.151, attn_loss: 1.19090\n",
      "[  141] iter, [0.548952] epoch, classifer loss: 2.240, attn_loss: 1.19059\n",
      "[  161] iter, [0.627374] epoch, classifer loss: 2.231, attn_loss: 1.18905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-158:\n",
      "Process Process-157:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-075b8eccdc06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresnet_attn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mresnet_attn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_k_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_attn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-1a1184bfd602>\u001b[0m in \u001b[0;36mtrain_k_epoch\u001b[0;34m(k, add_attn, score_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mclf_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mattn_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_attn_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0madd_attn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-f98b7bc42673>\u001b[0m in \u001b[0;36mcompute_attn_loss\u001b[0;34m(n_params)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mattns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_params_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'attn_weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     penality = sum([torch.pow(t - 1,2).mean() for t in attns])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpenality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_lambda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-f98b7bc42673>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mattns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_params_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'attn_weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     penality = sum([torch.pow(t - 1,2).mean() for t in attns])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpenality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_lambda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "turn_off_grad_except(['fc', 'attn_weights'])\n",
    "turn_on_layer4_conv_weight()\n",
    "resnet_attn.eval()\n",
    "resnet_attn.layer4.train()\n",
    "train_k_epoch(50,score_epoch=True, add_attn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:14<00:00,  3.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_accu': 0.0, 'val_accu': 0.5872291904218928}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_attn_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lambda = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_off_grad_except(['attn_weights','fc', 'layer4'])\n",
    "resnet_attn.eval()\n",
    "train_k_epoch(5,score_epoch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
