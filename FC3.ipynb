{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for param in resnet50.parameters():\n",
    "#     param.requires_grad = False\n",
    "# fc_num_in = resnet50.fc.in_features\n",
    "# print(fc_num_in)\n",
    "#Add more linear layers after resnet50\n",
    "class resnet50_3FC(nn.Module):\n",
    "    def __init__(self, resnet):\n",
    "        super(resnet50_3FC, self).__init__()\n",
    "        self.resnet = resnet\n",
    "        self.linear1 = nn.Linear(2048, 512)\n",
    "        self.resnet.fc = self.linear1\n",
    "        self.fc1_drop = nn.Dropout(p=0.1)\n",
    "#         self.linear2 = nn.Linear(1024, 256)\n",
    "#         self.fc2_drop = nn.Dropout(p=0.1)\n",
    "        self.linear3 = nn.Linear(512, 144)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.resnet.forward(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc1_drop(x)\n",
    "#         x = F.relu(self.linear2(x))\n",
    "#         x = self.fc2_drop(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Train, test, validation Split\n",
    "from PIL import Image\n",
    "import shutil\n",
    "data_split = False\n",
    "if data_split:\n",
    "    DATA_DIR = './Amphibia/train'\n",
    "    i = 1\n",
    "    for dir_path,dirs, files in os.walk(DATA_DIR):\n",
    "        print(i)\n",
    "        i+=1\n",
    "        for f in files:\n",
    "            if f.endswith('.jpg'):\n",
    "                k = np.random.rand()\n",
    "                if k <= 0.15:\n",
    "                    folder = 'test'\n",
    "                elif k <= 0.3:\n",
    "                    folder = 'val'\n",
    "                else:\n",
    "                    folder = 'train'\n",
    "                img = Image.open(os.path.join(dir_path, f))\n",
    "                img = img.resize((224, 224), Image.ANTIALIAS)\n",
    "                img.save(os.path.join('/Users/ryancheng/Desktop/cs194-129/project/data',folder,dir_path[-4:],f))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 8161, 'val': 1754}\n"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = './data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n",
    "                                             shuffle=True, num_workers=2)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "print(dataset_sizes)\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_time = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs), end=\" \")\n",
    "        #print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "#             for m in model.modules():\n",
    "#                 if isinstance(m, nn.BatchNorm2d):\n",
    "#                     m.eval()\n",
    "#                 else:\n",
    "#                     m.train()\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0]*inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc), end=\" \") \n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        e_time = time.time() - epoch_time\n",
    "        print('time: {:.0f}m {:.0f}s'.format(\n",
    "                e_time // 60, e_time%60))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = resnet50\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "resnet_FC = resnet50_3FC(resnet50).cuda()\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, resnet_FC.parameters()), lr=0.01)\n",
    "# print(list(filter(lambda p: p.requires_grad, resnet_FC.parameters())))\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 train Loss: 4.4876 Acc: 0.0594 val Loss: 5.0387 Acc: 0.0462 time: 0m 50s\n",
      "Epoch 2/50 train Loss: 4.2399 Acc: 0.0654 val Loss: 4.2037 Acc: 0.0764 time: 0m 52s\n",
      "Epoch 3/50 train Loss: 4.2002 Acc: 0.0701 val Loss: 4.1602 Acc: 0.0827 time: 0m 54s\n",
      "Epoch 4/50 train Loss: 4.1707 Acc: 0.0788 val Loss: 4.1267 Acc: 0.0832 time: 0m 54s\n",
      "Epoch 5/50 train Loss: 4.1324 Acc: 0.0853 val Loss: 4.4065 Acc: 0.0787 time: 0m 54s\n",
      "Epoch 6/50 train Loss: 4.1204 Acc: 0.0892 val Loss: 4.2281 Acc: 0.0946 time: 0m 55s\n",
      "Epoch 7/50 train Loss: 4.1088 Acc: 0.0857 val Loss: 4.7015 Acc: 0.0867 time: 0m 54s\n",
      "Epoch 8/50 train Loss: 4.1130 Acc: 0.0891 val Loss: 4.0514 Acc: 0.0981 time: 0m 55s\n",
      "Epoch 9/50 train Loss: 4.0840 Acc: 0.0935 val Loss: 4.0452 Acc: 0.1078 time: 0m 55s\n",
      "Epoch 10/50 train Loss: 4.0766 Acc: 0.0921 val Loss: 4.0510 Acc: 0.0981 time: 0m 55s\n",
      "Epoch 11/50 train Loss: 4.0635 Acc: 0.0945 val Loss: 4.0690 Acc: 0.0981 time: 0m 55s\n",
      "Epoch 12/50 train Loss: 4.0532 Acc: 0.0968 val Loss: 4.0324 Acc: 0.0998 time: 0m 55s\n",
      "Epoch 13/50 train Loss: 4.0370 Acc: 0.0946 val Loss: 4.0174 Acc: 0.1089 time: 0m 55s\n",
      "Epoch 14/50 train Loss: 4.0184 Acc: 0.0978 val Loss: 4.0113 Acc: 0.0958 time: 0m 55s\n",
      "Epoch 15/50 train Loss: 4.0254 Acc: 0.0972 val Loss: 4.0408 Acc: 0.0952 time: 0m 55s\n",
      "Epoch 16/50 train Loss: 3.9982 Acc: 0.1029 val Loss: 4.0040 Acc: 0.1055 time: 0m 55s\n",
      "Epoch 17/50 train Loss: 3.9744 Acc: 0.1026 val Loss: 4.1174 Acc: 0.0941 time: 0m 55s\n",
      "Epoch 18/50 train Loss: 3.9709 Acc: 0.1042 val Loss: 3.9624 Acc: 0.1003 time: 0m 55s\n",
      "Epoch 19/50 train Loss: 3.9464 Acc: 0.1068 val Loss: 4.1423 Acc: 0.0844 time: 0m 55s\n",
      "Epoch 20/50 train Loss: 3.9529 Acc: 0.1078 val Loss: 3.9189 Acc: 0.1106 time: 0m 55s\n",
      "Epoch 21/50 train Loss: 3.9625 Acc: 0.1028 val Loss: 4.0483 Acc: 0.0992 time: 0m 54s\n",
      "Epoch 22/50 train Loss: 3.9166 Acc: 0.1137 val Loss: 3.9533 Acc: 0.1129 time: 0m 55s\n",
      "Epoch 23/50 train Loss: 3.9158 Acc: 0.1091 val Loss: 3.9409 Acc: 0.1078 time: 0m 55s\n",
      "Epoch 24/50 train Loss: 3.9155 Acc: 0.1106 val Loss: 3.9562 Acc: 0.1083 time: 0m 54s\n",
      "Epoch 25/50 train Loss: 3.9365 Acc: 0.1038 val Loss: 3.9016 Acc: 0.1157 time: 0m 54s\n",
      "Epoch 26/50 train Loss: 3.8862 Acc: 0.1109 val Loss: 3.9130 Acc: 0.1078 time: 0m 54s\n",
      "Epoch 27/50 train Loss: 3.8664 Acc: 0.1061 val Loss: 3.8794 Acc: 0.1203 time: 0m 55s\n",
      "Epoch 28/50 train Loss: 3.8566 Acc: 0.1127 val Loss: 3.8949 Acc: 0.1266 time: 0m 54s\n",
      "Epoch 29/50 train Loss: 3.8526 Acc: 0.1146 val Loss: 3.8807 Acc: 0.1243 time: 0m 54s\n",
      "Epoch 30/50 train Loss: 3.8284 Acc: 0.1111 val Loss: 3.9210 Acc: 0.1146 time: 0m 54s\n",
      "Epoch 31/50 train Loss: 3.8161 Acc: 0.1203 val Loss: 4.0106 Acc: 0.1100 time: 0m 53s\n",
      "Epoch 32/50 train Loss: 3.8009 Acc: 0.1174 val Loss: 3.8709 Acc: 0.1192 time: 0m 53s\n",
      "Epoch 33/50 train Loss: 3.7995 Acc: 0.1235 val Loss: 3.9022 Acc: 0.1135 time: 0m 54s\n",
      "Epoch 34/50 train Loss: 3.7573 Acc: 0.1263 val Loss: 3.8312 Acc: 0.1231 time: 0m 53s\n",
      "Epoch 35/50 train Loss: 3.7415 Acc: 0.1280 val Loss: 3.8439 Acc: 0.1442 time: 0m 53s\n",
      "Epoch 36/50 train Loss: 3.7251 Acc: 0.1269 val Loss: 3.9358 Acc: 0.1294 time: 0m 54s\n",
      "Epoch 37/50 train Loss: 3.6908 Acc: 0.1385 val Loss: 3.8690 Acc: 0.1488 time: 0m 53s\n",
      "Epoch 38/50 train Loss: 3.6799 Acc: 0.1437 val Loss: 3.8974 Acc: 0.1226 time: 0m 53s\n",
      "Epoch 39/50 train Loss: 3.6575 Acc: 0.1485 val Loss: 3.7766 Acc: 0.1494 time: 0m 54s\n",
      "Epoch 40/50 "
     ]
    }
   ],
   "source": [
    "resnet50 = train_model(resnet_FC, criterion, optimizer_ft, None, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
