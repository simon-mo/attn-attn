{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AttentionModule import Conv2d_Attn\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models, datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_pretrained = models.resnet50(pretrained=True)\n",
    "nn.Conv2d = Conv2d_Attn\n",
    "resnet_attn = models.resnet50()\n",
    "resnet_attn.load_state_dict(resnet_pretrained.state_dict(), strict=False)\n",
    "resnet_attn.fc = nn.Linear(resnet_attn.fc.in_features, 144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(resnet_attn, 'fresh_resnet_attn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_attn = torch.load('fresh_resnet_attn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This block turns 'layer1.0.downsample.0.weight' to 'layer1[0].downsample[0].weight'\n",
    "param_keys = list(resnet_attn.state_dict().keys())\n",
    "formatted_keys = []\n",
    "for k in param_keys:\n",
    "    found = re.findall(r'\\.[\\d]{1,2}\\.', k)\n",
    "    if len(found):\n",
    "        for f in found:\n",
    "            k = k.replace(f, '[{}].'.format(f.strip('.')))\n",
    "    formatted_keys.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This block turn off gradient up for all params except attn_weights\n",
    "def turn_off_grad_except(lst=[]):\n",
    "    for k in formatted_keys:\n",
    "        obj = eval('resnet_attn.'+k)\n",
    "        for kw in lst:\n",
    "            if not kw in k:\n",
    "                obj.requires_grad = False\n",
    "            else:\n",
    "                obj.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     normalize])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root='./data/train', transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_imgs = len(trainset.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet_attn = resnet_attn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of attention parameters 26560\n"
     ]
    }
   ],
   "source": [
    "total_attn_params = 0\n",
    "for k in formatted_keys:\n",
    "    obj = eval('resnet_attn.'+k)\n",
    "    if 'attn_weights' in k:\n",
    "        total_attn_params += np.prod(obj.shape)\n",
    "print(\"Total number of attention parameters\", total_attn_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the attention parameters to diverge from 1, therefore we penalize element-wise square loss as $\\lambda (1 \\times \\text{# params} - (x - 1)^2)$\n",
    "\n",
    "But this is too big a number,\n",
    "let's try: \n",
    "$- (x - 1)^2$ for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lambda = 1e-2 #set default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params_objs(name, net='resnet_attn'):\n",
    "    res = []\n",
    "    for k in formatted_keys:\n",
    "        obj = eval(f'{net}.'+k)\n",
    "        if name in k:\n",
    "            res.append(obj)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attn_loss(n_params=26560):\n",
    "    attns = get_params_objs('attn_weights')\n",
    "    penality = sum([torch.pow(t - 1,2).mean() for t in attns])\n",
    "    return _lambda*(- penality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_k_epoch(epoch, add_attn=True):\n",
    "    cls_criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, resnet_attn.parameters()))\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_attn_loss = 0.0\n",
    "    \n",
    "    for k in range(epoch):\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            i += int(len(trainset)*k/batch_size)\n",
    "            \n",
    "            inputs, labels = data\n",
    "            inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = resnet_attn(inputs)\n",
    "            loss = cls_criterion(outputs, labels)\n",
    "            attn_loss = compute_attn_loss()\n",
    "            if add_attn:\n",
    "                loss += attn_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            running_loss += loss.data[0]\n",
    "            running_attn_loss += attn_loss.data[0]\n",
    "\n",
    "            if i % print_every == 0:\n",
    "                print('[%5d] iter, [%2f] epoch, avg loss: %.3f, attn_loss: %.5f ' %\n",
    "                      (i + 1, \n",
    "                       i*batch_size/total_imgs, \n",
    "                       running_loss/print_every, \n",
    "                       running_attn_loss/print_every))\n",
    "                running_loss = 0.0\n",
    "                running_attn_loss = 0.0\n",
    "        print(score(resnet_attn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def score(net, folder='val', batch_size=batch_size):\n",
    "    valset = torchvision.datasets.ImageFolder(root='./data/{}'.format(folder), transform=transform)\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "    \n",
    "    val_correct = 0\n",
    "    \n",
    "    for inp, label in tqdm(iter(valloader)):\n",
    "        _, idx = net(Variable(inp).cuda()).max(1)\n",
    "        val_correct += int(sum(idx.cpu().data == label))\n",
    "    \n",
    "    return {\n",
    "        'val_accu': val_correct/len(valset)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now start with a new model\n",
    "- Trian fc, train attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_attn = torch.load('fresh_resnet_attn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fc():\n",
    "    turn_off_grad_except(['fc'])\n",
    "    resnet_attn.eval() \n",
    "    train_k_epoch(1, add_attn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_attn():\n",
    "    turn_off_grad_except(['attn_weights'])\n",
    "    resnet_attn.eval() \n",
    "    _lambda = 1\n",
    "    train_k_epoch(1, add_attn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, avg loss: 0.505, attn_loss: 0.00000 \n",
      "[   11] iter, [0.039211] epoch, avg loss: 4.777, attn_loss: 0.00000 \n",
      "[   21] iter, [0.078422] epoch, avg loss: 4.251, attn_loss: 0.00000 \n",
      "[   31] iter, [0.117633] epoch, avg loss: 4.373, attn_loss: 0.00000 \n",
      "[   41] iter, [0.156844] epoch, avg loss: 4.044, attn_loss: 0.00000 \n",
      "[   51] iter, [0.196054] epoch, avg loss: 3.723, attn_loss: 0.00000 \n",
      "[   61] iter, [0.235265] epoch, avg loss: 3.707, attn_loss: 0.00000 \n",
      "[   71] iter, [0.274476] epoch, avg loss: 3.712, attn_loss: 0.00000 \n",
      "[   81] iter, [0.313687] epoch, avg loss: 3.551, attn_loss: 0.00000 \n",
      "[   91] iter, [0.352898] epoch, avg loss: 3.507, attn_loss: 0.00000 \n",
      "[  101] iter, [0.392109] epoch, avg loss: 3.530, attn_loss: 0.00000 \n",
      "[  111] iter, [0.431320] epoch, avg loss: 3.140, attn_loss: 0.00000 \n",
      "[  121] iter, [0.470531] epoch, avg loss: 3.263, attn_loss: 0.00000 \n",
      "[  131] iter, [0.509741] epoch, avg loss: 3.357, attn_loss: 0.00000 \n",
      "[  141] iter, [0.548952] epoch, avg loss: 3.307, attn_loss: 0.00000 \n",
      "[  151] iter, [0.588163] epoch, avg loss: 3.099, attn_loss: 0.00000 \n",
      "[  161] iter, [0.627374] epoch, avg loss: 3.188, attn_loss: 0.00000 \n",
      "[  171] iter, [0.666585] epoch, avg loss: 3.257, attn_loss: 0.00000 \n",
      "[  181] iter, [0.705796] epoch, avg loss: 2.988, attn_loss: 0.00000 \n",
      "[  191] iter, [0.745007] epoch, avg loss: 3.007, attn_loss: 0.00000 \n",
      "[  201] iter, [0.784218] epoch, avg loss: 2.946, attn_loss: 0.00000 \n",
      "[  211] iter, [0.823429] epoch, avg loss: 3.015, attn_loss: 0.00000 \n",
      "[  221] iter, [0.862639] epoch, avg loss: 2.953, attn_loss: 0.00000 \n",
      "[  231] iter, [0.901850] epoch, avg loss: 2.777, attn_loss: 0.00000 \n",
      "[  241] iter, [0.941061] epoch, avg loss: 2.835, attn_loss: 0.00000 \n",
      "[  251] iter, [0.980272] epoch, avg loss: 3.093, attn_loss: 0.00000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:13<00:00,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_accu': 0.3363740022805017}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, avg loss: 0.229, attn_loss: 0.00000 \n",
      "[   11] iter, [0.039211] epoch, avg loss: 2.292, attn_loss: -0.00000 \n",
      "[   21] iter, [0.078422] epoch, avg loss: 2.514, attn_loss: -0.00002 \n",
      "[   31] iter, [0.117633] epoch, avg loss: 2.449, attn_loss: -0.00003 \n",
      "[   41] iter, [0.156844] epoch, avg loss: 2.404, attn_loss: -0.00004 \n",
      "[   51] iter, [0.196054] epoch, avg loss: 2.201, attn_loss: -0.00005 \n",
      "[   61] iter, [0.235265] epoch, avg loss: 2.535, attn_loss: -0.00006 \n",
      "[   71] iter, [0.274476] epoch, avg loss: 2.430, attn_loss: -0.00007 \n",
      "[   81] iter, [0.313687] epoch, avg loss: 2.199, attn_loss: -0.00009 \n",
      "[   91] iter, [0.352898] epoch, avg loss: 1.990, attn_loss: -0.00010 \n",
      "[  101] iter, [0.392109] epoch, avg loss: 2.253, attn_loss: -0.00012 \n",
      "[  111] iter, [0.431320] epoch, avg loss: 2.047, attn_loss: -0.00014 \n",
      "[  121] iter, [0.470531] epoch, avg loss: 2.287, attn_loss: -0.00015 \n",
      "[  131] iter, [0.509741] epoch, avg loss: 2.283, attn_loss: -0.00016 \n",
      "[  141] iter, [0.548952] epoch, avg loss: 2.294, attn_loss: -0.00018 \n",
      "[  151] iter, [0.588163] epoch, avg loss: 2.272, attn_loss: -0.00020 \n",
      "[  161] iter, [0.627374] epoch, avg loss: 2.197, attn_loss: -0.00021 \n",
      "[  171] iter, [0.666585] epoch, avg loss: 2.095, attn_loss: -0.00023 \n",
      "[  181] iter, [0.705796] epoch, avg loss: 2.346, attn_loss: -0.00025 \n",
      "[  191] iter, [0.745007] epoch, avg loss: 2.113, attn_loss: -0.00027 \n",
      "[  201] iter, [0.784218] epoch, avg loss: 2.144, attn_loss: -0.00029 \n",
      "[  211] iter, [0.823429] epoch, avg loss: 2.139, attn_loss: -0.00031 \n",
      "[  221] iter, [0.862639] epoch, avg loss: 2.110, attn_loss: -0.00033 \n",
      "[  231] iter, [0.901850] epoch, avg loss: 2.197, attn_loss: -0.00035 \n",
      "[  241] iter, [0.941061] epoch, avg loss: 2.038, attn_loss: -0.00037 \n",
      "[  251] iter, [0.980272] epoch, avg loss: 2.256, attn_loss: -0.00039 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:13<00:00,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_accu': 0.395096921322691}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_fc()\n",
    "train_attn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRUNE_PORTION = 1/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weights = get_params_objs('attn_weights')\n",
    "attn_masks = get_params_objs('attn_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = attn_weights[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, rank = torch.sort(t, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_idxs = rank[:int(len(rank)*PRUNE_PORTION)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_masks[0].data[prune_idxs.squeeze()] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "(0 ,0 ,.,.) = \n",
       "  0\n",
       "\n",
       "(1 ,0 ,.,.) = \n",
       "  0\n",
       "\n",
       "(2 ,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(3 ,0 ,.,.) = \n",
       "  0\n",
       "\n",
       "(4 ,0 ,.,.) = \n",
       "  0\n",
       "\n",
       "(5 ,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(6 ,0 ,.,.) = \n",
       "  0\n",
       "\n",
       "(7 ,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(8 ,0 ,.,.) = \n",
       "  0\n",
       "\n",
       "(9 ,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(10,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(11,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(12,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(13,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(14,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(15,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(16,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(17,0 ,.,.) = \n",
       "  0\n",
       "\n",
       "(18,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(19,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(20,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(21,0 ,.,.) = \n",
       "  0\n",
       "\n",
       "(22,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(23,0 ,.,.) = \n",
       "  0\n",
       "\n",
       "(24,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(25,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(26,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(27,0 ,.,.) = \n",
       "  0\n",
       "\n",
       "(28,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(29,0 ,.,.) = \n",
       "  0\n",
       "\n",
       "(30,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(31,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(32,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(33,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(34,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(35,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(36,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(37,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(38,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(39,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(40,0 ,.,.) = \n",
       "  0\n",
       "\n",
       "(41,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(42,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(43,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(44,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(45,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(46,0 ,.,.) = \n",
       "  0\n",
       "\n",
       "(47,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(48,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(49,0 ,.,.) = \n",
       "  0\n",
       "\n",
       "(50,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(51,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(52,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(53,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(54,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(55,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(56,0 ,.,.) = \n",
       "  0\n",
       "\n",
       "(57,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(58,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(59,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(60,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(61,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(62,0 ,.,.) = \n",
       "  1\n",
       "\n",
       "(63,0 ,.,.) = \n",
       "  0\n",
       "[torch.cuda.FloatTensor of size 64x1x1x1 (GPU 0)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_masks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
