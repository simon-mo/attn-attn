{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from AttentionModule import Conv2d_Attn\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models, datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_pretrained = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn.Conv2d = Conv2d_Attn\n",
    "resnet_attn = models.resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet_attn.load_state_dict(resnet_pretrained.state_dict(), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change batchnorm behavior\n",
    "resnet_attn = resnet_attn.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This block turns 'layer1.0.downsample.0.weight' to 'layer1[0].downsample[0].weight'\n",
    "param_keys = list(resnet_attn.state_dict().keys())\n",
    "formatted_keys = []\n",
    "for k in param_keys:\n",
    "    found = re.findall(r'\\.[\\d]{1,2}\\.', k)\n",
    "    if len(found):\n",
    "        for f in found:\n",
    "            k = k.replace(f, '[{}].'.format(f.strip('.')))\n",
    "    formatted_keys.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This block turn off gradient up for all params except attn_weights\n",
    "def turn_off_grad_except_attn():\n",
    "    for k in formatted_keys:\n",
    "        obj = eval('resnet_attn.'+k)\n",
    "        if not 'attn_weights' in k:\n",
    "            obj.requires_grad = False\n",
    "        else:\n",
    "            obj.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def turn_off_al_grad():\n",
    "    for k in formatted_keys:\n",
    "        obj = eval('resnet_attn.'+k)\n",
    "        obj.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "turn_off_al_grad()\n",
    "resnet_attn.fc = nn.Linear(resnet_attn.fc.in_features, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.Resize(224),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, resnet_attn.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet_attn = resnet_attn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reg_lambda = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just train the FC layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  200] loss: 1.303, attn_mean: 1.000, attn_std: 0.000\n",
      "[  400] loss: 0.769, attn_mean: 1.000, attn_std: 0.000\n",
      "[  600] loss: 0.752, attn_mean: 1.000, attn_std: 0.000\n",
      "[  800] loss: 0.723, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 1000] loss: 0.741, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 1200] loss: 0.652, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 1400] loss: 0.626, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 1600] loss: 0.695, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 1800] loss: 0.588, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 2000] loss: 0.611, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 2200] loss: 0.592, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 2400] loss: 0.681, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 2600] loss: 0.609, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 2800] loss: 0.639, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 3000] loss: 0.599, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 3200] loss: 0.632, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 3400] loss: 0.600, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 3600] loss: 0.608, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 3800] loss: 0.562, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 4000] loss: 0.640, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 4200] loss: 0.462, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 4400] loss: 0.548, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 4600] loss: 0.557, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 4800] loss: 0.556, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 5000] loss: 0.586, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 5200] loss: 0.561, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 5400] loss: 0.520, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 5600] loss: 0.585, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 5800] loss: 0.635, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 6000] loss: 0.442, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 6200] loss: 0.529, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 6400] loss: 0.552, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 6600] loss: 0.628, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 6800] loss: 0.522, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 7000] loss: 0.614, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 7200] loss: 0.566, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 7400] loss: 0.559, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 7600] loss: 0.621, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 7800] loss: 0.623, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 8000] loss: 0.520, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 8200] loss: 0.585, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 8400] loss: 0.590, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 8600] loss: 0.560, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 8800] loss: 0.559, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 9000] loss: 0.528, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 9200] loss: 0.531, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 9400] loss: 0.547, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 9600] loss: 0.599, attn_mean: 1.000, attn_std: 0.000\n",
      "[ 9800] loss: 0.575, attn_mean: 1.000, attn_std: 0.000\n",
      "[10000] loss: 0.549, attn_mean: 1.000, attn_std: 0.000\n",
      "[10200] loss: 0.522, attn_mean: 1.000, attn_std: 0.000\n",
      "[10400] loss: 0.620, attn_mean: 1.000, attn_std: 0.000\n",
      "[10600] loss: 0.595, attn_mean: 1.000, attn_std: 0.000\n",
      "[10800] loss: 0.507, attn_mean: 1.000, attn_std: 0.000\n",
      "[11000] loss: 0.556, attn_mean: 1.000, attn_std: 0.000\n",
      "[11200] loss: 0.578, attn_mean: 1.000, attn_std: 0.000\n",
      "[11400] loss: 0.514, attn_mean: 1.000, attn_std: 0.000\n",
      "[11600] loss: 0.683, attn_mean: 1.000, attn_std: 0.000\n",
      "[11800] loss: 0.568, attn_mean: 1.000, attn_std: 0.000\n",
      "[12000] loss: 0.583, attn_mean: 1.000, attn_std: 0.000\n",
      "[12200] loss: 0.506, attn_mean: 1.000, attn_std: 0.000\n",
      "[12400] loss: 0.548, attn_mean: 1.000, attn_std: 0.000\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for i, data in enumerate(trainloader, 0):\n",
    "    # get the inputs\n",
    "    inputs, labels = data\n",
    "\n",
    "    # wrap them in Variable\n",
    "    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = resnet_attn(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "#     for k in formatted_keys:\n",
    "#         if 'attn_weights' in k:\n",
    "#             obj = eval('resnet_attn.'+k)\n",
    "#             loss += reg_lambda*torch.norm(obj, p=1)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    # print statistics\n",
    "    running_loss += loss.data[0]\n",
    "    if i % 200 == 199:    # print every 2000 mini-batches\n",
    "        attn_mean = []\n",
    "        attn_std = []\n",
    "\n",
    "        for k in formatted_keys:\n",
    "            if 'attn_weights' in k:\n",
    "                obj = eval('resnet_attn.'+k)\n",
    "                attn_mean.append(obj.data.mean())\n",
    "                attn_std.append(obj.data.std())\n",
    "            \n",
    "        print('[%5d] loss: %.3f, attn_mean: %.3f, attn_std: %.3f' %\n",
    "              (i + 1, running_loss / 200, np.mean(attn_mean), np.std(attn_std)))\n",
    "        running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 82 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = resnet_attn(Variable(images).cuda())\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted.cpu() == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "turn_off_grad_except_attn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  200] loss: 6.002, attn_mean: 0.871, attn_std: 0.092\n",
      "[  400] loss: 5.954, attn_mean: 0.860, attn_std: 0.109\n",
      "[  600] loss: 5.870, attn_mean: 0.856, attn_std: 0.110\n",
      "[  800] loss: 5.811, attn_mean: 0.853, attn_std: 0.110\n",
      "[ 1000] loss: 5.707, attn_mean: 0.850, attn_std: 0.111\n",
      "[ 1200] loss: 5.668, attn_mean: 0.847, attn_std: 0.111\n",
      "[ 1400] loss: 5.646, attn_mean: 0.844, attn_std: 0.111\n",
      "[ 1600] loss: 5.603, attn_mean: 0.841, attn_std: 0.111\n",
      "[ 1800] loss: 5.598, attn_mean: 0.838, attn_std: 0.111\n",
      "[ 2000] loss: 5.523, attn_mean: 0.836, attn_std: 0.110\n",
      "[ 2200] loss: 5.496, attn_mean: 0.833, attn_std: 0.110\n",
      "[ 2400] loss: 5.467, attn_mean: 0.831, attn_std: 0.110\n",
      "[ 2600] loss: 5.444, attn_mean: 0.828, attn_std: 0.110\n",
      "[ 2800] loss: 5.393, attn_mean: 0.826, attn_std: 0.110\n",
      "[ 3000] loss: 5.386, attn_mean: 0.823, attn_std: 0.110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-10:\n",
      "  File \"/home/seg-image/anaconda3/envs/simon/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "Process Process-9:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seg-image/anaconda3/envs/simon/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/seg-image/anaconda3/envs/simon/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/seg-image/anaconda3/envs/simon/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/seg-image/anaconda3/envs/simon/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/seg-image/anaconda3/envs/simon/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/seg-image/anaconda3/envs/simon/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/seg-image/anaconda3/envs/simon/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/seg-image/anaconda3/envs/simon/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/seg-image/anaconda3/envs/simon/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/seg-image/anaconda3/envs/simon/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/seg-image/anaconda3/envs/simon/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <bound method DataLoaderIter.__del__ of <torch.utils.data.dataloader.DataLoaderIter object at 0x7f743145f278>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seg-image/anaconda3/envs/simon/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 333, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/seg-image/anaconda3/envs/simon/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 319, in _shutdown_workers\n",
      "    self.data_queue.get()\n",
      "  File \"/home/seg-image/anaconda3/envs/simon/lib/python3.6/multiprocessing/queues.py\", line 344, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/seg-image/anaconda3/envs/simon/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/home/seg-image/anaconda3/envs/simon/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/home/seg-image/anaconda3/envs/simon/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/home/seg-image/anaconda3/envs/simon/lib/python3.6/multiprocessing/connection.py\", line 487, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/home/seg-image/anaconda3/envs/simon/lib/python3.6/multiprocessing/connection.py\", line 614, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-39b4e82d3666>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m199\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# print every 2000 mini-batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mattn_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "reg_lambda = 5e-7\n",
    "\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, resnet_attn.parameters()))\n",
    "\n",
    "for i, data in enumerate(trainloader, 0):\n",
    "    # get the inputs\n",
    "    inputs, labels = data\n",
    "\n",
    "    # wrap them in Variable\n",
    "    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = resnet_attn(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    for k in formatted_keys:\n",
    "        if 'attn_weights' in k:\n",
    "            obj = eval('resnet_attn.'+k)\n",
    "            loss += reg_lambda*torch.norm(obj, p=1)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    # print statistics\n",
    "    running_loss += loss.data[0]\n",
    "    if i % 200 == 199:    # print every 2000 mini-batches\n",
    "        attn_mean = []\n",
    "        attn_std = []\n",
    "\n",
    "        for k in formatted_keys:\n",
    "            if 'attn_weights' in k:\n",
    "                obj = eval('resnet_attn.'+k)\n",
    "                attn_mean.append(obj.data.mean())\n",
    "                attn_std.append(obj.data.std())\n",
    "            \n",
    "        print('[%5d] loss: %.3f, attn_mean: %.3f, attn_std: %.3f' %\n",
    "              (i + 1, running_loss / 200, np.mean(attn_mean), np.std(attn_std)))\n",
    "        running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 84 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = resnet_attn(Variable(images).cuda())\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted.cpu() == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training run @ April 10, 2018 – 21:27:\n",
    "- We need to add regularization to move the attention around. \n",
    "- Otherwise, the attention will just stay where they are and be happy with it. \n",
    "- Todo:\n",
    "    - Figure out the correct attn size for a conv tensor of size (channel_out, channel_in, H, W)\n",
    "    - Figure out the correct initialization + penalization scheme. It's 1 for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
