{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from AttentionModule import Conv2d_Attn\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models, datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_pretrained = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn.Conv2d = Conv2d_Attn\n",
    "resnet_attn = models.resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet_attn.load_state_dict(resnet_pretrained.state_dict(), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change batchnorm behavior\n",
    "# resnet_attn = resnet_attn.eval() \n",
    "# Don't want to do that because bn needs to be re-trained as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This block turns 'layer1.0.downsample.0.weight' to 'layer1[0].downsample[0].weight'\n",
    "param_keys = list(resnet_attn.state_dict().keys())\n",
    "formatted_keys = []\n",
    "for k in param_keys:\n",
    "    found = re.findall(r'\\.[\\d]{1,2}\\.', k)\n",
    "    if len(found):\n",
    "        for f in found:\n",
    "            k = k.replace(f, '[{}].'.format(f.strip('.')))\n",
    "    formatted_keys.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This block turn off gradient up for all params except attn_weights\n",
    "def turn_off_grad_except(lst=[]):\n",
    "    for k in formatted_keys:\n",
    "        obj = eval('resnet_attn.'+k)\n",
    "        for kw in lst:\n",
    "            if not kw in k:\n",
    "                obj.requires_grad = False\n",
    "            else:\n",
    "                obj.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet_attn.fc = nn.Linear(resnet_attn.fc.in_features, 144)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     normalize])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root='./data/train', transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_imgs = len(trainset.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet_attn = resnet_attn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of attention parameters 26560\n"
     ]
    }
   ],
   "source": [
    "total_attn_params = 0\n",
    "for k in formatted_keys:\n",
    "    obj = eval('resnet_attn.'+k)\n",
    "    if 'attn_weights' in k:\n",
    "        total_attn_params += np.prod(obj.shape)\n",
    "print(\"Total number of attention parameters\", total_attn_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the attention parameters to diverge from 1, therefore we penalize element-wise square loss as $\\lambda (1 \\times \\text{# params} - (x - 1)^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lambda = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params_objs(name, net='resnet_attn'):\n",
    "    res = []\n",
    "    for k in formatted_keys:\n",
    "        obj = eval(f'{net}.'+k)\n",
    "        if name in k:\n",
    "            res.append(obj)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attn_loss(n_params=26560):\n",
    "    attns = get_params_objs('attn_weights')\n",
    "    penality = sum([torch.pow(t - 1,2).mean() for t in attns])\n",
    "    return _lambda*(n_params - penality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(add_attn=True):\n",
    "    cls_criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, resnet_attn.parameters()))\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_attn_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet_attn(inputs)\n",
    "        loss = cls_criterion(outputs, labels)\n",
    "        attn_loss = compute_attn_loss()\n",
    "        if add_attn:\n",
    "            loss += attn_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        running_loss += loss.data[0]\n",
    "        running_attn_loss += attn_loss.data[0]\n",
    "\n",
    "        if i % print_every == 0:\n",
    "            print('[%5d] iter, [%2f] epoch, avg loss: %.3f, attn_loss: %.5f ' %\n",
    "                  (i + 1, i*batch_size/total_imgs, running_loss/print_every, running_attn_loss/print_every))\n",
    "            running_loss = 0.0\n",
    "            running_attn_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a fresh fc layer. \n",
    "`turn_off_grad_except([])` turns off grads for all weights but the fc layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, avg loss: 0.995, attn_loss: 53.12000 \n",
      "[    6] iter, [0.019605] epoch, avg loss: 4.829, attn_loss: 265.60001 \n",
      "[   11] iter, [0.039211] epoch, avg loss: 4.714, attn_loss: 265.60001 \n",
      "[   16] iter, [0.058816] epoch, avg loss: 4.777, attn_loss: 265.60001 \n",
      "[   21] iter, [0.078422] epoch, avg loss: 4.605, attn_loss: 265.60001 \n",
      "[   26] iter, [0.098027] epoch, avg loss: 4.198, attn_loss: 265.60001 \n",
      "[   31] iter, [0.117633] epoch, avg loss: 3.953, attn_loss: 265.60001 \n",
      "[   36] iter, [0.137238] epoch, avg loss: 4.067, attn_loss: 265.60001 \n",
      "[   41] iter, [0.156844] epoch, avg loss: 3.808, attn_loss: 265.60001 \n",
      "[   46] iter, [0.176449] epoch, avg loss: 3.970, attn_loss: 265.60001 \n",
      "[   51] iter, [0.196054] epoch, avg loss: 3.776, attn_loss: 265.60001 \n",
      "[   56] iter, [0.215660] epoch, avg loss: 3.797, attn_loss: 265.60001 \n",
      "[   61] iter, [0.235265] epoch, avg loss: 3.523, attn_loss: 265.60001 \n",
      "[   66] iter, [0.254871] epoch, avg loss: 3.797, attn_loss: 265.60001 \n",
      "[   71] iter, [0.274476] epoch, avg loss: 3.867, attn_loss: 265.60001 \n",
      "[   76] iter, [0.294082] epoch, avg loss: 3.516, attn_loss: 265.60001 \n",
      "[   81] iter, [0.313687] epoch, avg loss: 3.432, attn_loss: 265.60001 \n",
      "[   86] iter, [0.333292] epoch, avg loss: 3.444, attn_loss: 265.60001 \n",
      "[   91] iter, [0.352898] epoch, avg loss: 3.779, attn_loss: 265.60001 \n",
      "[   96] iter, [0.372503] epoch, avg loss: 3.408, attn_loss: 265.60001 \n",
      "[  101] iter, [0.392109] epoch, avg loss: 3.444, attn_loss: 265.60001 \n",
      "[  106] iter, [0.411714] epoch, avg loss: 3.526, attn_loss: 265.60001 \n",
      "[  111] iter, [0.431320] epoch, avg loss: 3.314, attn_loss: 265.60001 \n",
      "[  116] iter, [0.450925] epoch, avg loss: 3.090, attn_loss: 265.60001 \n",
      "[  121] iter, [0.470531] epoch, avg loss: 3.213, attn_loss: 265.60001 \n",
      "[  126] iter, [0.490136] epoch, avg loss: 3.077, attn_loss: 265.60001 \n",
      "[  131] iter, [0.509741] epoch, avg loss: 3.478, attn_loss: 265.60001 \n",
      "[  136] iter, [0.529347] epoch, avg loss: 3.170, attn_loss: 265.60001 \n",
      "[  141] iter, [0.548952] epoch, avg loss: 3.322, attn_loss: 265.60001 \n",
      "[  146] iter, [0.568558] epoch, avg loss: 3.245, attn_loss: 265.60001 \n",
      "[  151] iter, [0.588163] epoch, avg loss: 2.968, attn_loss: 265.60001 \n",
      "[  156] iter, [0.607769] epoch, avg loss: 3.099, attn_loss: 265.60001 \n",
      "[  161] iter, [0.627374] epoch, avg loss: 2.911, attn_loss: 265.60001 \n",
      "[  166] iter, [0.646980] epoch, avg loss: 3.040, attn_loss: 265.60001 \n",
      "[  171] iter, [0.666585] epoch, avg loss: 3.103, attn_loss: 265.60001 \n",
      "[  176] iter, [0.686190] epoch, avg loss: 3.193, attn_loss: 265.60001 \n",
      "[  181] iter, [0.705796] epoch, avg loss: 3.002, attn_loss: 265.60001 \n",
      "[  186] iter, [0.725401] epoch, avg loss: 3.010, attn_loss: 265.60001 \n",
      "[  191] iter, [0.745007] epoch, avg loss: 2.896, attn_loss: 265.60001 \n",
      "[  196] iter, [0.764612] epoch, avg loss: 2.951, attn_loss: 265.60001 \n",
      "[  201] iter, [0.784218] epoch, avg loss: 2.730, attn_loss: 265.60001 \n",
      "[  206] iter, [0.803823] epoch, avg loss: 3.060, attn_loss: 265.60001 \n",
      "[  211] iter, [0.823429] epoch, avg loss: 3.136, attn_loss: 265.60001 \n",
      "[  216] iter, [0.843034] epoch, avg loss: 3.012, attn_loss: 265.60001 \n",
      "[  221] iter, [0.862639] epoch, avg loss: 2.823, attn_loss: 265.60001 \n",
      "[  226] iter, [0.882245] epoch, avg loss: 3.022, attn_loss: 265.60001 \n",
      "[  231] iter, [0.901850] epoch, avg loss: 3.176, attn_loss: 265.60001 \n",
      "[  236] iter, [0.921456] epoch, avg loss: 2.553, attn_loss: 265.60001 \n",
      "[  241] iter, [0.941061] epoch, avg loss: 3.104, attn_loss: 265.60001 \n",
      "[  246] iter, [0.960667] epoch, avg loss: 2.681, attn_loss: 265.60001 \n",
      "[  251] iter, [0.980272] epoch, avg loss: 2.898, attn_loss: 265.60001 \n",
      "[  256] iter, [0.999877] epoch, avg loss: 3.945, attn_loss: 265.60001 \n"
     ]
    }
   ],
   "source": [
    "turn_off_grad_except(['fc'])\n",
    "resnet_attn.eval() # Turn off batchnorm\n",
    "train_one_epoch(add_attn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(net=resnet_attn, batch_size=batch_size):\n",
    "    trainset = torchvision.datasets.ImageFolder(root='./data/train', transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "    \n",
    "    valset = torchvision.datasets.ImageFolder(root='./data/val', transform=transform)\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "    \n",
    "    train_correct = 0\n",
    "    val_correct = 0\n",
    "    \n",
    "    for inp, label in tqdm(iter(trainloader)):\n",
    "        _, idx = net(Variable(inp).cuda()).max(1)\n",
    "        train_correct += int(sum(idx.cpu().data == label))\n",
    "    \n",
    "    for inp, label in tqdm(iter(valloader)):\n",
    "        _, idx = net(Variable(inp).cuda()).max(1)\n",
    "        val_correct += int(sum(idx.cpu().data == label))\n",
    "    \n",
    "    return {\n",
    "        'train_accu': train_correct/len(trainset),\n",
    "        'val_accu': val_correct/len(valset)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/128 [00:00<?, ?it/s]\u001b[A\n",
      "Exception ignored in: <bound method DataLoaderIter.__del__ of <torch.utils.data.dataloader.DataLoaderIter object at 0x7f728e4da6d8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 333, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 319, in _shutdown_workers\n",
      "    self.data_queue.get()\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 487, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 614, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "100%|██████████| 128/128 [01:02<00:00,  2.04it/s]\n",
      "100%|██████████| 28/28 [00:13<00:00,  2.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_accu': 0.34603602499693664, 'val_accu': 0.2913340935005701}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, avg loss: 1.202, attn_loss: 0.53120 \n",
      "[    6] iter, [0.019605] epoch, avg loss: 5.620, attn_loss: 2.65600 \n",
      "[   11] iter, [0.039211] epoch, avg loss: 5.551, attn_loss: 2.65600 \n",
      "[   16] iter, [0.058816] epoch, avg loss: 5.662, attn_loss: 2.65600 \n",
      "[   21] iter, [0.078422] epoch, avg loss: 5.460, attn_loss: 2.65600 \n",
      "[   26] iter, [0.098027] epoch, avg loss: 5.253, attn_loss: 2.65600 \n",
      "[   31] iter, [0.117633] epoch, avg loss: 5.532, attn_loss: 2.65600 \n",
      "[   36] iter, [0.137238] epoch, avg loss: 5.282, attn_loss: 2.65600 \n",
      "[   41] iter, [0.156844] epoch, avg loss: 5.439, attn_loss: 2.65600 \n",
      "[   46] iter, [0.176449] epoch, avg loss: 5.473, attn_loss: 2.65600 \n",
      "[   51] iter, [0.196054] epoch, avg loss: 5.185, attn_loss: 2.65600 \n",
      "[   56] iter, [0.215660] epoch, avg loss: 5.185, attn_loss: 2.65600 \n",
      "[   61] iter, [0.235265] epoch, avg loss: 5.482, attn_loss: 2.65600 \n",
      "[   66] iter, [0.254871] epoch, avg loss: 5.303, attn_loss: 2.65600 \n",
      "[   71] iter, [0.274476] epoch, avg loss: 5.097, attn_loss: 2.65600 \n",
      "[   76] iter, [0.294082] epoch, avg loss: 5.326, attn_loss: 2.65600 \n",
      "[   81] iter, [0.313687] epoch, avg loss: 5.416, attn_loss: 2.65600 \n",
      "[   86] iter, [0.333292] epoch, avg loss: 5.213, attn_loss: 2.65600 \n",
      "[   91] iter, [0.352898] epoch, avg loss: 5.082, attn_loss: 2.65600 \n",
      "[   96] iter, [0.372503] epoch, avg loss: 5.022, attn_loss: 2.65600 \n",
      "[  101] iter, [0.392109] epoch, avg loss: 5.068, attn_loss: 2.65600 \n",
      "[  106] iter, [0.411714] epoch, avg loss: 5.145, attn_loss: 2.65600 \n",
      "[  111] iter, [0.431320] epoch, avg loss: 5.017, attn_loss: 2.65600 \n",
      "[  116] iter, [0.450925] epoch, avg loss: 5.115, attn_loss: 2.65600 \n",
      "[  121] iter, [0.470531] epoch, avg loss: 4.804, attn_loss: 2.65600 \n",
      "[  126] iter, [0.490136] epoch, avg loss: 4.897, attn_loss: 2.65600 \n",
      "[  131] iter, [0.509741] epoch, avg loss: 5.057, attn_loss: 2.65600 \n",
      "[  136] iter, [0.529347] epoch, avg loss: 4.946, attn_loss: 2.65600 \n",
      "[  141] iter, [0.548952] epoch, avg loss: 5.066, attn_loss: 2.65600 \n",
      "[  146] iter, [0.568558] epoch, avg loss: 4.880, attn_loss: 2.65600 \n",
      "[  151] iter, [0.588163] epoch, avg loss: 5.180, attn_loss: 2.65600 \n",
      "[  156] iter, [0.607769] epoch, avg loss: 4.972, attn_loss: 2.65600 \n",
      "[  161] iter, [0.627374] epoch, avg loss: 4.957, attn_loss: 2.65600 \n",
      "[  166] iter, [0.646980] epoch, avg loss: 5.119, attn_loss: 2.65600 \n",
      "[  171] iter, [0.666585] epoch, avg loss: 5.006, attn_loss: 2.65600 \n",
      "[  176] iter, [0.686190] epoch, avg loss: 4.943, attn_loss: 2.65600 \n",
      "[  181] iter, [0.705796] epoch, avg loss: 5.006, attn_loss: 2.65600 \n",
      "[  186] iter, [0.725401] epoch, avg loss: 5.214, attn_loss: 2.65600 \n",
      "[  191] iter, [0.745007] epoch, avg loss: 4.966, attn_loss: 2.65600 \n",
      "[  196] iter, [0.764612] epoch, avg loss: 5.000, attn_loss: 2.65600 \n",
      "[  201] iter, [0.784218] epoch, avg loss: 5.271, attn_loss: 2.65600 \n",
      "[  206] iter, [0.803823] epoch, avg loss: 4.997, attn_loss: 2.65600 \n",
      "[  211] iter, [0.823429] epoch, avg loss: 5.064, attn_loss: 2.65600 \n",
      "[  216] iter, [0.843034] epoch, avg loss: 4.873, attn_loss: 2.65600 \n",
      "[  221] iter, [0.862639] epoch, avg loss: 4.901, attn_loss: 2.65600 \n",
      "[  226] iter, [0.882245] epoch, avg loss: 4.813, attn_loss: 2.65600 \n",
      "[  231] iter, [0.901850] epoch, avg loss: 5.098, attn_loss: 2.65600 \n",
      "[  236] iter, [0.921456] epoch, avg loss: 5.010, attn_loss: 2.65600 \n",
      "[  241] iter, [0.941061] epoch, avg loss: 4.926, attn_loss: 2.65600 \n",
      "[  246] iter, [0.960667] epoch, avg loss: 4.971, attn_loss: 2.65600 \n",
      "[  251] iter, [0.980272] epoch, avg loss: 5.018, attn_loss: 2.65600 \n",
      "[  256] iter, [0.999877] epoch, avg loss: 5.440, attn_loss: 2.65600 \n"
     ]
    }
   ],
   "source": [
    "turn_off_grad_except(['attn_weights','bn'])\n",
    "resnet_attn = resnet_attn.train()\n",
    "_lambda = 1e-4\n",
    "train_one_epoch(add_attn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:05<00:00,  1.97it/s]\n",
      "100%|██████████| 28/28 [00:14<00:00,  1.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_accu': 0.47714740840583264, 'val_accu': 0.40364880273660203}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
