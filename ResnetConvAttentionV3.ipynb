{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from AttentionModule import Conv2d_Attn\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models, datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_pretrained = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn.Conv2d = Conv2d_Attn\n",
    "resnet_attn = models.resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet_attn.load_state_dict(resnet_pretrained.state_dict(), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change batchnorm behavior\n",
    "# resnet_attn = resnet_attn.eval() \n",
    "# Don't want to do that because bn needs to be re-trained as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This block turns 'layer1.0.downsample.0.weight' to 'layer1[0].downsample[0].weight'\n",
    "param_keys = list(resnet_attn.state_dict().keys())\n",
    "formatted_keys = []\n",
    "for k in param_keys:\n",
    "    found = re.findall(r'\\.[\\d]{1,2}\\.', k)\n",
    "    if len(found):\n",
    "        for f in found:\n",
    "            k = k.replace(f, '[{}].'.format(f.strip('.')))\n",
    "    formatted_keys.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This block turn off gradient up for all params except attn_weights\n",
    "def turn_off_grad_except(lst=[]):\n",
    "    for k in formatted_keys:\n",
    "        obj = eval('resnet_attn.'+k)\n",
    "        for kw in lst:\n",
    "            if not kw in k:\n",
    "                obj.requires_grad = False\n",
    "            else:\n",
    "                obj.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet_attn.fc = nn.Linear(resnet_attn.fc.in_features, 144)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     normalize])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root='./data/train', transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_imgs = len(trainset.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet_attn = resnet_attn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of attention parameters 26560\n"
     ]
    }
   ],
   "source": [
    "total_attn_params = 0\n",
    "for k in formatted_keys:\n",
    "    obj = eval('resnet_attn.'+k)\n",
    "    if 'attn_weights' in k:\n",
    "        total_attn_params += np.prod(obj.shape)\n",
    "print(\"Total number of attention parameters\", total_attn_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the attention parameters to diverge from 1, therefore we penalize element-wise square loss as $\\lambda (1 \\times \\text{# params} - (x - 1)^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lambda = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params_objs(name, net='resnet_attn'):\n",
    "    res = []\n",
    "    for k in formatted_keys:\n",
    "        obj = eval(f'{net}.'+k)\n",
    "        if name in k:\n",
    "            res.append(obj)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attn_loss(n_params=26560):\n",
    "    attns = get_params_objs('attn_weights')\n",
    "    penality = sum([torch.pow(t - 1,2).mean() for t in attns])\n",
    "    return _lambda*(n_params - penality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(add_attn=True):\n",
    "    cls_criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, resnet_attn.parameters()))\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_attn_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet_attn(inputs)\n",
    "        loss = cls_criterion(outputs, labels)\n",
    "        attn_loss = compute_attn_loss()\n",
    "        if add_attn:\n",
    "            loss += attn_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        running_loss += loss.data[0]\n",
    "        running_attn_loss += attn_loss.data[0]\n",
    "\n",
    "        if i % print_every == 0:\n",
    "            print('[%5d] iter, [%2f] epoch, avg loss: %.3f, attn_loss: %.5f ' %\n",
    "                  (i + 1, i*batch_size/total_imgs, running_loss/print_every, running_attn_loss/print_every))\n",
    "            running_loss = 0.0\n",
    "            running_attn_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a fresh fc layer. \n",
    "`turn_off_grad_except([])` turns off grads for all weights but the fc layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, avg loss: 1.032, attn_loss: 53.12000 \n",
      "[    6] iter, [0.019605] epoch, avg loss: 4.804, attn_loss: 265.60001 \n",
      "[   11] iter, [0.039211] epoch, avg loss: 4.892, attn_loss: 265.60001 \n",
      "[   16] iter, [0.058816] epoch, avg loss: 4.647, attn_loss: 265.60001 \n",
      "[   21] iter, [0.078422] epoch, avg loss: 4.314, attn_loss: 265.60001 \n",
      "[   26] iter, [0.098027] epoch, avg loss: 4.091, attn_loss: 265.60001 \n",
      "[   31] iter, [0.117633] epoch, avg loss: 3.889, attn_loss: 265.60001 \n",
      "[   36] iter, [0.137238] epoch, avg loss: 3.989, attn_loss: 265.60001 \n",
      "[   41] iter, [0.156844] epoch, avg loss: 3.793, attn_loss: 265.60001 \n",
      "[   46] iter, [0.176449] epoch, avg loss: 3.981, attn_loss: 265.60001 \n",
      "[   51] iter, [0.196054] epoch, avg loss: 3.458, attn_loss: 265.60001 \n",
      "[   56] iter, [0.215660] epoch, avg loss: 3.794, attn_loss: 265.60001 \n",
      "[   61] iter, [0.235265] epoch, avg loss: 3.646, attn_loss: 265.60001 \n",
      "[   66] iter, [0.254871] epoch, avg loss: 3.412, attn_loss: 265.60001 \n",
      "[   71] iter, [0.274476] epoch, avg loss: 3.327, attn_loss: 265.60001 \n",
      "[   76] iter, [0.294082] epoch, avg loss: 3.425, attn_loss: 265.60001 \n",
      "[   81] iter, [0.313687] epoch, avg loss: 3.552, attn_loss: 265.60001 \n",
      "[   86] iter, [0.333292] epoch, avg loss: 3.366, attn_loss: 265.60001 \n",
      "[   91] iter, [0.352898] epoch, avg loss: 3.363, attn_loss: 265.60001 \n",
      "[   96] iter, [0.372503] epoch, avg loss: 3.421, attn_loss: 265.60001 \n",
      "[  101] iter, [0.392109] epoch, avg loss: 3.548, attn_loss: 265.60001 \n",
      "[  106] iter, [0.411714] epoch, avg loss: 3.341, attn_loss: 265.60001 \n",
      "[  111] iter, [0.431320] epoch, avg loss: 3.366, attn_loss: 265.60001 \n",
      "[  116] iter, [0.450925] epoch, avg loss: 3.459, attn_loss: 265.60001 \n",
      "[  121] iter, [0.470531] epoch, avg loss: 3.166, attn_loss: 265.60001 \n",
      "[  126] iter, [0.490136] epoch, avg loss: 3.060, attn_loss: 265.60001 \n",
      "[  131] iter, [0.509741] epoch, avg loss: 2.961, attn_loss: 265.60001 \n",
      "[  136] iter, [0.529347] epoch, avg loss: 3.273, attn_loss: 265.60001 \n",
      "[  141] iter, [0.548952] epoch, avg loss: 3.490, attn_loss: 265.60001 \n",
      "[  146] iter, [0.568558] epoch, avg loss: 2.984, attn_loss: 265.60001 \n",
      "[  151] iter, [0.588163] epoch, avg loss: 3.098, attn_loss: 265.60001 \n",
      "[  156] iter, [0.607769] epoch, avg loss: 3.110, attn_loss: 265.60001 \n",
      "[  161] iter, [0.627374] epoch, avg loss: 3.092, attn_loss: 265.60001 \n",
      "[  166] iter, [0.646980] epoch, avg loss: 3.245, attn_loss: 265.60001 \n",
      "[  171] iter, [0.666585] epoch, avg loss: 3.122, attn_loss: 265.60001 \n",
      "[  176] iter, [0.686190] epoch, avg loss: 3.288, attn_loss: 265.60001 \n",
      "[  181] iter, [0.705796] epoch, avg loss: 3.050, attn_loss: 265.60001 \n",
      "[  186] iter, [0.725401] epoch, avg loss: 2.901, attn_loss: 265.60001 \n",
      "[  191] iter, [0.745007] epoch, avg loss: 3.103, attn_loss: 265.60001 \n",
      "[  196] iter, [0.764612] epoch, avg loss: 3.137, attn_loss: 265.60001 \n",
      "[  201] iter, [0.784218] epoch, avg loss: 3.091, attn_loss: 265.60001 \n",
      "[  206] iter, [0.803823] epoch, avg loss: 3.043, attn_loss: 265.60001 \n",
      "[  211] iter, [0.823429] epoch, avg loss: 3.025, attn_loss: 265.60001 \n",
      "[  216] iter, [0.843034] epoch, avg loss: 2.988, attn_loss: 265.60001 \n",
      "[  221] iter, [0.862639] epoch, avg loss: 3.005, attn_loss: 265.60001 \n",
      "[  226] iter, [0.882245] epoch, avg loss: 2.935, attn_loss: 265.60001 \n",
      "[  231] iter, [0.901850] epoch, avg loss: 2.853, attn_loss: 265.60001 \n",
      "[  236] iter, [0.921456] epoch, avg loss: 2.991, attn_loss: 265.60001 \n",
      "[  241] iter, [0.941061] epoch, avg loss: 2.829, attn_loss: 265.60001 \n",
      "[  246] iter, [0.960667] epoch, avg loss: 2.777, attn_loss: 265.60001 \n",
      "[  251] iter, [0.980272] epoch, avg loss: 2.791, attn_loss: 265.60001 \n",
      "[  256] iter, [0.999877] epoch, avg loss: 3.334, attn_loss: 265.60001 \n"
     ]
    }
   ],
   "source": [
    "turn_off_grad_except(['fc'])\n",
    "resnet_attn.eval() # Turn off batchnorm\n",
    "train_one_epoch(add_attn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(net=resnet_attn, batch_size=batch_size):\n",
    "    trainset = torchvision.datasets.ImageFolder(root='./data/train', transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "    \n",
    "    valset = torchvision.datasets.ImageFolder(root='./data/val', transform=transform)\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "    \n",
    "    train_correct = 0\n",
    "    val_correct = 0\n",
    "    \n",
    "    for inp, label in tqdm(iter(trainloader)):\n",
    "        _, idx = net(Variable(inp).cuda()).max(1)\n",
    "        train_correct += int(sum(idx.cpu().data == label))\n",
    "    \n",
    "    for inp, label in tqdm(iter(valloader)):\n",
    "        _, idx = net(Variable(inp).cuda()).max(1)\n",
    "        val_correct += int(sum(idx.cpu().data == label))\n",
    "    \n",
    "    return {\n",
    "        'train_accu': train_correct/len(trainset),\n",
    "        'val_accu': val_correct/len(valset)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:02<00:00,  2.05it/s]\n",
      "100%|██████████| 28/28 [00:13<00:00,  2.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_accu': 0.38377649797818897, 'val_accu': 0.33352337514253133}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, avg loss: 1.207, attn_loss: 0.53120 \n",
      "[    6] iter, [0.019605] epoch, avg loss: 5.745, attn_loss: 2.65600 \n",
      "[   11] iter, [0.039211] epoch, avg loss: 5.688, attn_loss: 2.65600 \n",
      "[   16] iter, [0.058816] epoch, avg loss: 5.379, attn_loss: 2.65600 \n",
      "[   21] iter, [0.078422] epoch, avg loss: 5.470, attn_loss: 2.65600 \n",
      "[   26] iter, [0.098027] epoch, avg loss: 5.416, attn_loss: 2.65600 \n",
      "[   31] iter, [0.117633] epoch, avg loss: 5.480, attn_loss: 2.65600 \n",
      "[   36] iter, [0.137238] epoch, avg loss: 5.273, attn_loss: 2.65600 \n",
      "[   41] iter, [0.156844] epoch, avg loss: 5.344, attn_loss: 2.65600 \n",
      "[   46] iter, [0.176449] epoch, avg loss: 5.305, attn_loss: 2.65600 \n",
      "[   51] iter, [0.196054] epoch, avg loss: 5.274, attn_loss: 2.65600 \n",
      "[   56] iter, [0.215660] epoch, avg loss: 5.231, attn_loss: 2.65600 \n",
      "[   61] iter, [0.235265] epoch, avg loss: 5.209, attn_loss: 2.65600 \n",
      "[   66] iter, [0.254871] epoch, avg loss: 5.318, attn_loss: 2.65600 \n",
      "[   71] iter, [0.274476] epoch, avg loss: 5.303, attn_loss: 2.65600 \n",
      "[   76] iter, [0.294082] epoch, avg loss: 5.181, attn_loss: 2.65600 \n",
      "[   81] iter, [0.313687] epoch, avg loss: 5.002, attn_loss: 2.65600 \n",
      "[   86] iter, [0.333292] epoch, avg loss: 5.055, attn_loss: 2.65600 \n",
      "[   91] iter, [0.352898] epoch, avg loss: 5.376, attn_loss: 2.65600 \n",
      "[   96] iter, [0.372503] epoch, avg loss: 5.205, attn_loss: 2.65600 \n",
      "[  101] iter, [0.392109] epoch, avg loss: 5.066, attn_loss: 2.65600 \n",
      "[  106] iter, [0.411714] epoch, avg loss: 5.161, attn_loss: 2.65600 \n",
      "[  111] iter, [0.431320] epoch, avg loss: 5.390, attn_loss: 2.65600 \n",
      "[  116] iter, [0.450925] epoch, avg loss: 5.283, attn_loss: 2.65600 \n",
      "[  121] iter, [0.470531] epoch, avg loss: 5.120, attn_loss: 2.65600 \n",
      "[  126] iter, [0.490136] epoch, avg loss: 4.843, attn_loss: 2.65600 \n",
      "[  131] iter, [0.509741] epoch, avg loss: 5.007, attn_loss: 2.65600 \n",
      "[  136] iter, [0.529347] epoch, avg loss: 4.948, attn_loss: 2.65600 \n",
      "[  141] iter, [0.548952] epoch, avg loss: 5.121, attn_loss: 2.65600 \n",
      "[  146] iter, [0.568558] epoch, avg loss: 4.943, attn_loss: 2.65600 \n",
      "[  151] iter, [0.588163] epoch, avg loss: 5.153, attn_loss: 2.65600 \n",
      "[  156] iter, [0.607769] epoch, avg loss: 5.274, attn_loss: 2.65600 \n",
      "[  161] iter, [0.627374] epoch, avg loss: 5.181, attn_loss: 2.65600 \n",
      "[  166] iter, [0.646980] epoch, avg loss: 5.083, attn_loss: 2.65600 \n",
      "[  171] iter, [0.666585] epoch, avg loss: 5.214, attn_loss: 2.65600 \n",
      "[  176] iter, [0.686190] epoch, avg loss: 5.117, attn_loss: 2.65600 \n",
      "[  181] iter, [0.705796] epoch, avg loss: 4.992, attn_loss: 2.65600 \n",
      "[  186] iter, [0.725401] epoch, avg loss: 5.019, attn_loss: 2.65600 \n",
      "[  191] iter, [0.745007] epoch, avg loss: 4.966, attn_loss: 2.65600 \n",
      "[  196] iter, [0.764612] epoch, avg loss: 4.976, attn_loss: 2.65600 \n",
      "[  201] iter, [0.784218] epoch, avg loss: 4.795, attn_loss: 2.65600 \n",
      "[  206] iter, [0.803823] epoch, avg loss: 4.770, attn_loss: 2.65600 \n",
      "[  211] iter, [0.823429] epoch, avg loss: 4.878, attn_loss: 2.65600 \n",
      "[  216] iter, [0.843034] epoch, avg loss: 4.831, attn_loss: 2.65600 \n",
      "[  221] iter, [0.862639] epoch, avg loss: 4.981, attn_loss: 2.65600 \n",
      "[  226] iter, [0.882245] epoch, avg loss: 5.034, attn_loss: 2.65600 \n",
      "[  231] iter, [0.901850] epoch, avg loss: 5.249, attn_loss: 2.65600 \n",
      "[  236] iter, [0.921456] epoch, avg loss: 4.958, attn_loss: 2.65600 \n",
      "[  241] iter, [0.941061] epoch, avg loss: 4.823, attn_loss: 2.65600 \n",
      "[  246] iter, [0.960667] epoch, avg loss: 4.757, attn_loss: 2.65600 \n",
      "[  251] iter, [0.980272] epoch, avg loss: 4.942, attn_loss: 2.65600 \n",
      "[  256] iter, [0.999877] epoch, avg loss: 4.993, attn_loss: 2.65600 \n"
     ]
    }
   ],
   "source": [
    "turn_off_grad_except(['attn_weights','bn'])\n",
    "resnet_attn = resnet_attn.train()\n",
    "_lambda = 1e-4\n",
    "train_one_epoch(add_attn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:05<00:00,  1.97it/s]\n",
      "100%|██████████| 28/28 [00:14<00:00,  1.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_accu': 0.4773924764122044, 'val_accu': 0.40250855188141393}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1] iter, [0.000000] epoch, avg loss: 5312.389, attn_loss: 5312.00000 \n",
      "[    6] iter, [0.019605] epoch, avg loss: 26562.083, attn_loss: 26560.00000 \n",
      "[   11] iter, [0.039211] epoch, avg loss: 26562.094, attn_loss: 26560.00000 \n",
      "[   16] iter, [0.058816] epoch, avg loss: 26562.080, attn_loss: 26559.99883 \n",
      "[   21] iter, [0.078422] epoch, avg loss: 26562.244, attn_loss: 26559.99805 \n",
      "[   26] iter, [0.098027] epoch, avg loss: 26562.171, attn_loss: 26559.99805 \n",
      "[   31] iter, [0.117633] epoch, avg loss: 26562.136, attn_loss: 26559.99805 \n",
      "[   36] iter, [0.137238] epoch, avg loss: 26561.817, attn_loss: 26559.99609 \n",
      "[   41] iter, [0.156844] epoch, avg loss: 26561.794, attn_loss: 26559.99609 \n",
      "[   46] iter, [0.176449] epoch, avg loss: 26562.011, attn_loss: 26559.99570 \n",
      "[   51] iter, [0.196054] epoch, avg loss: 26561.921, attn_loss: 26559.99414 \n",
      "[   56] iter, [0.215660] epoch, avg loss: 26562.111, attn_loss: 26559.99414 \n",
      "[   61] iter, [0.235265] epoch, avg loss: 26562.123, attn_loss: 26559.99219 \n",
      "[   66] iter, [0.254871] epoch, avg loss: 26561.777, attn_loss: 26559.99180 \n",
      "[   71] iter, [0.274476] epoch, avg loss: 26561.996, attn_loss: 26559.99023 \n",
      "[   76] iter, [0.294082] epoch, avg loss: 26561.882, attn_loss: 26559.98867 \n",
      "[   81] iter, [0.313687] epoch, avg loss: 26561.724, attn_loss: 26559.98711 \n",
      "[   86] iter, [0.333292] epoch, avg loss: 26562.193, attn_loss: 26559.98516 \n",
      "[   91] iter, [0.352898] epoch, avg loss: 26561.843, attn_loss: 26559.98359 \n",
      "[   96] iter, [0.372503] epoch, avg loss: 26561.685, attn_loss: 26559.98125 \n",
      "[  101] iter, [0.392109] epoch, avg loss: 26562.018, attn_loss: 26559.97891 \n",
      "[  106] iter, [0.411714] epoch, avg loss: 26562.102, attn_loss: 26559.97617 \n",
      "[  111] iter, [0.431320] epoch, avg loss: 26561.828, attn_loss: 26559.97383 \n",
      "[  116] iter, [0.450925] epoch, avg loss: 26561.480, attn_loss: 26559.97070 \n",
      "[  121] iter, [0.470531] epoch, avg loss: 26561.859, attn_loss: 26559.96797 \n",
      "[  126] iter, [0.490136] epoch, avg loss: 26561.971, attn_loss: 26559.96445 \n",
      "[  131] iter, [0.509741] epoch, avg loss: 26561.593, attn_loss: 26559.96094 \n",
      "[  136] iter, [0.529347] epoch, avg loss: 26561.627, attn_loss: 26559.95742 \n",
      "[  141] iter, [0.548952] epoch, avg loss: 26561.898, attn_loss: 26559.95352 \n",
      "[  146] iter, [0.568558] epoch, avg loss: 26561.888, attn_loss: 26559.94961 \n",
      "[  151] iter, [0.588163] epoch, avg loss: 26562.125, attn_loss: 26559.94492 \n",
      "[  156] iter, [0.607769] epoch, avg loss: 26561.871, attn_loss: 26559.94102 \n",
      "[  161] iter, [0.627374] epoch, avg loss: 26561.618, attn_loss: 26559.93594 \n",
      "[  166] iter, [0.646980] epoch, avg loss: 26561.850, attn_loss: 26559.93008 \n",
      "[  171] iter, [0.666585] epoch, avg loss: 26561.967, attn_loss: 26559.92539 \n",
      "[  176] iter, [0.686190] epoch, avg loss: 26562.085, attn_loss: 26559.91953 \n",
      "[  181] iter, [0.705796] epoch, avg loss: 26561.624, attn_loss: 26559.91328 \n",
      "[  186] iter, [0.725401] epoch, avg loss: 26561.779, attn_loss: 26559.90742 \n",
      "[  191] iter, [0.745007] epoch, avg loss: 26561.889, attn_loss: 26559.90117 \n",
      "[  196] iter, [0.764612] epoch, avg loss: 26561.709, attn_loss: 26559.89414 \n",
      "[  201] iter, [0.784218] epoch, avg loss: 26561.681, attn_loss: 26559.88750 \n",
      "[  206] iter, [0.803823] epoch, avg loss: 26561.612, attn_loss: 26559.88008 \n",
      "[  211] iter, [0.823429] epoch, avg loss: 26561.850, attn_loss: 26559.87227 \n",
      "[  216] iter, [0.843034] epoch, avg loss: 26561.730, attn_loss: 26559.86445 \n",
      "[  221] iter, [0.862639] epoch, avg loss: 26562.245, attn_loss: 26559.85586 \n",
      "[  226] iter, [0.882245] epoch, avg loss: 26561.764, attn_loss: 26559.84766 \n",
      "[  231] iter, [0.901850] epoch, avg loss: 26561.613, attn_loss: 26559.83789 \n",
      "[  236] iter, [0.921456] epoch, avg loss: 26561.612, attn_loss: 26559.83008 \n",
      "[  241] iter, [0.941061] epoch, avg loss: 26561.610, attn_loss: 26559.82031 \n",
      "[  246] iter, [0.960667] epoch, avg loss: 26561.858, attn_loss: 26559.80859 \n",
      "[  251] iter, [0.980272] epoch, avg loss: 26561.680, attn_loss: 26559.79883 \n",
      "[  256] iter, [0.999877] epoch, avg loss: 26561.383, attn_loss: 26559.78789 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:03<00:00,  2.03it/s]\n",
      "100%|██████████| 28/28 [00:13<00:00,  2.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_accu': 0.5192991055017767, 'val_accu': 0.427594070695553}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turn_off_grad_except(['attn_weights'])\n",
    "resnet_attn = resnet_attn.eval()\n",
    "_lambda = 1\n",
    "train_one_epoch(add_attn=True)\n",
    "score(batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9920831 , 0.9934335 , 1.0174953 , 1.0028536 , 0.9993886 ,\n",
       "       0.99619156, 1.0068909 , 1.0230352 , 0.9964805 , 0.99543005,\n",
       "       1.0036072 , 0.97201735, 1.0118227 , 1.        , 1.0046093 ,\n",
       "       1.0039697 , 0.9995543 , 1.0046791 , 1.0027827 , 1.0176603 ,\n",
       "       1.02211   , 1.001126  , 1.0142523 , 1.0215573 , 1.0014066 ,\n",
       "       0.9899166 , 1.0183663 , 1.0128137 , 1.0150323 , 1.0450556 ,\n",
       "       1.0052605 , 0.82890725, 1.0075049 , 1.0083247 , 1.0341356 ,\n",
       "       0.9981748 , 1.0052088 , 0.98948526, 1.0258948 , 0.99799013,\n",
       "       0.99088335, 0.9929585 , 0.97616553, 1.0020766 , 1.009043  ,\n",
       "       0.99546564, 1.0090386 , 1.0029176 , 0.9877005 , 1.0169706 ,\n",
       "       1.0088778 , 1.0115087 , 0.9861459 , 1.0229034 , 0.98577136,\n",
       "       0.994887  , 0.99842876, 1.0175492 , 0.99294907, 0.9721664 ,\n",
       "       0.9978678 , 1.0024883 , 1.0015049 , 1.0037984 ], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_attn.conv1.attn_weights.cpu().data.numpy().squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thoughts:\n",
    "- It works. \n",
    "- Interleaving training works for now, but maybe it's fine if we just train it all together\n",
    "- We need to find a better loss to let attention diverge faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
